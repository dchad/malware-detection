{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Extraction of Features\n",
    "    Features sets will consist of:\n",
    "    - Entropy and file size from packed binaries.\n",
    "    - Entropy and file size from unpacked binaries.\n",
    "    - ASM features from disassembled unpacked binaries.\n",
    "    - Executable header features.\n",
    "    - Call Graph Features.\n",
    "    - Sample Statistics.\n",
    "    - PE packer type.\n",
    "    - Behavioural features from Cuckoo Sandbox reports.\n",
    "    - Memory features from Volatility reports.\n",
    "    \n",
    "    Training labels will be generated from ClamAV, Windows Defender and VirusTotal.com reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import os\n",
    "from csv import writer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy.misc\n",
    "import array\n",
    "import time as tm\n",
    "import re\n",
    "import subprocess as sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ext_drive = '/opt/vs/'\n",
    "tfiles = os.listdir(ext_drive + \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Generate Entropy and File Size of Packed Binaries and Non-Binary Files\n",
    "    Script: feature_extraction_entropy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Shannon's Entropy, https://en.wikipedia.org/wiki/Entropy_(information_theory)\n",
    "\n",
    "def calculate_entropy(byte_counts, total):\n",
    "    \n",
    "    entropy = 0.0\n",
    "\n",
    "    for count in byte_counts:\n",
    "        # If no bytes of this value were seen in the value, it doesn't affect\n",
    "        # the entropy of the file.\n",
    "        if count == 0:\n",
    "            continue\n",
    "        # p is the probability of seeing this byte in the file, as a floating-point number\n",
    "        p = 1.0 * count / total\n",
    "        entropy -= p * math.log(p, 256)\n",
    "    \n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def entropy_counter(byte_code):\n",
    "    \n",
    "    byte_counts = [0] * 256\n",
    "    code_length = len(byte_code)\n",
    "    \n",
    "    for i in range(len(byte_code)):\n",
    "        byte_counts[int(byte_code[i])] += 1\n",
    "        \n",
    "    entropy = calculate_entropy(byte_counts, code_length)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def sort_and_save_entropy_feature_file():\n",
    "    entropys = pd.read_csv('data/entropy-features.csv')\n",
    "    # DataFrame.sort() is deprecated, but this is an old version of pandas, does not have sort_values().\n",
    "    sorted_entropys = entropys.sort('file_name')\n",
    "    sorted_entropys.to_csv('data/sorted-entropy-features.csv', index=False)\n",
    "    sorted_entropys.head(20)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def combine_entropy_files():\n",
    "    # Function to combine the newly generated entropy files into one file:\n",
    "    # 1. list data directory\n",
    "    # 2. For each file in file list that matches (\\d\\d\\d\\d-entropy-features.csv)\n",
    "    # 3. Trim the filenames if necessary (should remove VirusShare_  prefix).\n",
    "    # 4. Concatenate the unsorted packer id feature files.\n",
    "    # 5. Sort and write to data/sorted-packer-id-features.csv\n",
    "    fop = open('data/entropy-features.csv','w')\n",
    "    fop.write('file_name,entropy,file_size\\n')\n",
    "    p1 = re.compile('\\d{3,5}-entropy-features-bin.csv') # This is the PID prefix for each file.\n",
    "    file_list = os.listdir('data/')\n",
    "    counter = 0\n",
    "    for file_name in file_list:\n",
    "        if p1.match(file_name):\n",
    "            fip = open('data/' + file_name, 'r')\n",
    "            in_lines = fip.readlines()\n",
    "            fop.writelines(in_lines)\n",
    "            counter += len(in_lines)\n",
    "            fip.close()\n",
    "            \n",
    "    print('Completed combine of {:d} entropy features.'.format(counter))  \n",
    "    \n",
    "    fop.close()\n",
    "    \n",
    "    sort_and_save_entropy_feature_file()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "# feature extraction for the binary files\n",
    "\n",
    "def extract_binary_features(tfiles):\n",
    "    #byte_files = [i for i in tfiles if '.bytes' in i]\n",
    "    ftot = len(tfiles)\n",
    "    \n",
    "    pid = os.getpid()\n",
    "    print('Process id:', pid)\n",
    "    feature_file = 'data/' + str(pid) + '-entropy-features-bin.csv' # entropy, file size, ngrams...   \n",
    "    print('feature file:', feature_file)\n",
    "    \n",
    "    feature_counts = []\n",
    "    with open(feature_file, 'w') as f:\n",
    "        # Write the column names for the csv file\n",
    "        fw = writer(f)\n",
    "        # Do this when combining the files.\n",
    "        #colnames = ['file_name'] + ['entropy'] + ['file_size'] \n",
    "        #fw.writerow(colnames)\n",
    "        \n",
    "        # Now iterate through the file list and extract the features from each file.\n",
    "        for idx, fname in enumerate(tfiles):\n",
    "            fasm = open(ext_drive + fname, 'rb')\n",
    "            filesize = os.path.getsize(ext_drive + fname)\n",
    "            in_bytes = fasm.read()\n",
    "            \n",
    "            # TODO: Do ngram extraction\n",
    "            # First do entropy calculations and filesize\n",
    "            # Convert the input array into a byte array to prevent type errors\n",
    "            # in entropy counter function.\n",
    "            in_bytes = bytearray(in_bytes)\n",
    "            #print(\"Type = {:s}\").format(type(in_bytes))\n",
    "            entropy = entropy_counter(in_bytes)\n",
    "            \n",
    "            count_vals = [entropy, filesize]\n",
    "            \n",
    "            feature_counts.append([fname[fname.find('_')+1:]] + count_vals)   \n",
    "            \n",
    "            fasm.close()\n",
    "            \n",
    "            # Print progress\n",
    "            if (idx+1) % 1000 == 0:\n",
    "                print(\"{:d} - {:d} of {:d} files processed.\".format(pid, idx + 1, ftot))\n",
    "                fw.writerows(feature_counts)\n",
    "                feature_counts = []\n",
    "                \n",
    "        # Write remaining files\n",
    "        if len(feature_counts) > 0:\n",
    "            fw.writerows(feature_counts)\n",
    "            feature_counts = []\n",
    "\n",
    "        print(\"Completed processing {:d} rows for feature file {:s}\".format(ftot,feature_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "# Now divide the train files into four groups for multiprocessing\n",
    "ext_drive = '/opt/vs/train/'\n",
    "tfiles = os.listdir(ext_drive)\n",
    "quart = len(tfiles)/4\n",
    "train1 = tfiles[:quart]\n",
    "train2 = tfiles[quart:(2*quart)]\n",
    "train3 = tfiles[(2*quart):(3*quart)]\n",
    "train4 = tfiles[(3*quart):]\n",
    "print(\"Files: {:d} - {:d} - {:d}\".format(len(tfiles), quart, (len(train1)+len(train2)+len(train3)+len(train4))))\n",
    "trains = [train1, train2, train3, train4]\n",
    "p = Pool(4)\n",
    "p.map(extract_binary_features, trains)\n",
    "combine_entropy_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: 65536 - 16384 - 65536\n",
      "('Process id:', 4152)\n",
      "('feature file:', 'data/4153-entropy-features-bin.csv')\n",
      "('feature file:', 'data/4152-entropy-features-bin.csv')\n",
      "('Process id:', 4153)\n",
      "('Process id:', 4154)\n",
      "('feature file:', 'data/4154-entropy-features-bin.csv')\n",
      "('Process id:', 4155)\n",
      "('feature file:', 'data/4155-entropy-features-bin.csv')\n",
      "4153 - 1000 of 16384 files processed.\n",
      "4152 - 1000 of 16384 files processed.\n",
      "4155 - 1000 of 16384 files processed.\n",
      "4154 - 1000 of 16384 files processed.\n",
      "4152 - 2000 of 16384 files processed.\n",
      "4153 - 2000 of 16384 files processed.\n",
      "4155 - 2000 of 16384 files processed.\n",
      "4154 - 2000 of 16384 files processed.\n",
      "4152 - 3000 of 16384 files processed.\n",
      "4155 - 3000 of 16384 files processed.\n",
      "4153 - 3000 of 16384 files processed.\n",
      "4154 - 3000 of 16384 files processed.\n",
      "4152 - 4000 of 16384 files processed.\n",
      "4155 - 4000 of 16384 files processed.\n",
      "4153 - 4000 of 16384 files processed.\n",
      "4154 - 4000 of 16384 files processed.\n",
      "4155 - 5000 of 16384 files processed.\n",
      "4152 - 5000 of 16384 files processed.\n",
      "4153 - 5000 of 16384 files processed.\n",
      "4154 - 5000 of 16384 files processed.\n",
      "4155 - 6000 of 16384 files processed.\n",
      "4152 - 6000 of 16384 files processed.\n",
      "4153 - 6000 of 16384 files processed.\n",
      "4154 - 6000 of 16384 files processed.\n",
      "4155 - 7000 of 16384 files processed.\n",
      "4152 - 7000 of 16384 files processed.\n",
      "4153 - 7000 of 16384 files processed.\n",
      "4154 - 7000 of 16384 files processed.\n",
      "4155 - 8000 of 16384 files processed.\n",
      "4153 - 8000 of 16384 files processed.\n",
      "4152 - 8000 of 16384 files processed.\n",
      "4154 - 8000 of 16384 files processed.\n",
      "4155 - 9000 of 16384 files processed.\n",
      "4153 - 9000 of 16384 files processed.\n",
      "4152 - 9000 of 16384 files processed.\n",
      "4154 - 9000 of 16384 files processed.\n",
      "4155 - 10000 of 16384 files processed.\n",
      "4154 - 10000 of 16384 files processed.\n",
      "4153 - 10000 of 16384 files processed.\n",
      "4152 - 10000 of 16384 files processed.\n",
      "4155 - 11000 of 16384 files processed.\n",
      "4154 - 11000 of 16384 files processed.\n",
      "4153 - 11000 of 16384 files processed.\n",
      "4152 - 11000 of 16384 files processed.\n",
      "4155 - 12000 of 16384 files processed.\n",
      "4154 - 12000 of 16384 files processed.\n",
      "4153 - 12000 of 16384 files processed.\n",
      "4152 - 12000 of 16384 files processed.\n",
      "4155 - 13000 of 16384 files processed.\n",
      "4154 - 13000 of 16384 files processed.\n",
      "4153 - 13000 of 16384 files processed.\n",
      "4155 - 14000 of 16384 files processed.\n",
      "4152 - 13000 of 16384 files processed.\n",
      "4154 - 14000 of 16384 files processed.\n",
      "4153 - 14000 of 16384 files processed.\n",
      "4152 - 14000 of 16384 files processed.\n",
      "4155 - 15000 of 16384 files processed.\n",
      "4154 - 15000 of 16384 files processed.\n",
      "4153 - 15000 of 16384 files processed.\n",
      "4155 - 16000 of 16384 files processed.\n",
      "4152 - 15000 of 16384 files processed.\n",
      "4154 - 16000 of 16384 files processed.\n",
      "Completed processing 16384 rows for feature file data/4155-entropy-features-bin.csv\n",
      "Completed processing 16384 rows for feature file data/4154-entropy-features-bin.csv\n",
      "4153 - 16000 of 16384 files processed.\n",
      "4152 - 16000 of 16384 files processed.\n",
      "Completed processing 16384 rows for feature file data/4153-entropy-features-bin.csv\n",
      "Completed processing 16384 rows for feature file data/4152-entropy-features-bin.csv\n",
      "Completed combine of 65536 entropy features.\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "# Now divide the train files into four groups for multiprocessing\n",
    "ext_drive = '/opt/vs/train2/'\n",
    "tfiles = os.listdir(ext_drive)\n",
    "quart = len(tfiles)/4\n",
    "train1 = tfiles[:quart]\n",
    "train2 = tfiles[quart:(2*quart)]\n",
    "train3 = tfiles[(2*quart):(3*quart)]\n",
    "train4 = tfiles[(3*quart):]\n",
    "print(\"Files: {:d} - {:d} - {:d}\".format(len(tfiles), quart, (len(train1)+len(train2)+len(train3)+len(train4))))\n",
    "trains = [train1, train2, train3, train4]\n",
    "p = Pool(4)\n",
    "p.map(extract_binary_features, trains)\n",
    "combine_entropy_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>entropy</th>\n",
       "      <th>file_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0    </th>\n",
       "      <td> 00002e640cafb741bea9a48eaee27d6f</td>\n",
       "      <td> 0.992174</td>\n",
       "      <td>  208860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1    </th>\n",
       "      <td> 000118d12cbf9ad6103e8b914a6e1ac3</td>\n",
       "      <td> 0.834382</td>\n",
       "      <td>  201600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2    </th>\n",
       "      <td> 0001776237ac37a69fcef93c1bac0988</td>\n",
       "      <td> 0.966021</td>\n",
       "      <td>  682192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65536</th>\n",
       "      <td> 00027c21667d9119a454df8cef2dc1c7</td>\n",
       "      <td> 0.666599</td>\n",
       "      <td>   18390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65537</th>\n",
       "      <td> 0003887ab64b8ae19ffa988638decac2</td>\n",
       "      <td> 0.903260</td>\n",
       "      <td> 1134320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3    </th>\n",
       "      <td> 000403e4e488356b7535cc613fbeb80b</td>\n",
       "      <td> 0.773787</td>\n",
       "      <td>  199168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65538</th>\n",
       "      <td> 0004376a62e22f6ad359467eb742b8ff</td>\n",
       "      <td> 0.803515</td>\n",
       "      <td>  149720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4    </th>\n",
       "      <td> 0004c8b2a0f4680a5694d74199b40ea2</td>\n",
       "      <td> 0.985592</td>\n",
       "      <td> 1165440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5    </th>\n",
       "      <td> 000595d8b586915c12053104cf845097</td>\n",
       "      <td> 0.841920</td>\n",
       "      <td>  264240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65539</th>\n",
       "      <td> 000634f03457d088c71dbffb897b1315</td>\n",
       "      <td> 0.957584</td>\n",
       "      <td> 1725502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65540</th>\n",
       "      <td> 00072ed24314e91b63b425b3dc572f50</td>\n",
       "      <td> 0.486112</td>\n",
       "      <td>  328093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65541</th>\n",
       "      <td> 00092d369958b67557da8661cc9093bc</td>\n",
       "      <td> 0.845657</td>\n",
       "      <td>  522936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6    </th>\n",
       "      <td> 00093d5fa5cb7ce77f6eaf39962daa12</td>\n",
       "      <td> 0.803481</td>\n",
       "      <td>  742064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7    </th>\n",
       "      <td> 00099926d51b44c6f8c93a48c2567891</td>\n",
       "      <td> 0.997032</td>\n",
       "      <td>  725288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65542</th>\n",
       "      <td> 0009a64f786fa29bfa6423278cc74f02</td>\n",
       "      <td> 0.996663</td>\n",
       "      <td>  671280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8    </th>\n",
       "      <td> 000a2db4762dc06628a086c9e117f884</td>\n",
       "      <td> 0.535436</td>\n",
       "      <td>   61551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65543</th>\n",
       "      <td> 000ac11fa7587b2316470b154254a219</td>\n",
       "      <td> 0.997824</td>\n",
       "      <td> 1874471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9    </th>\n",
       "      <td> 000ae2c63ba69fc93dfc395b40bfe03a</td>\n",
       "      <td> 0.899481</td>\n",
       "      <td>  487386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65544</th>\n",
       "      <td> 000ae90736a51c47543dcc6d8a735362</td>\n",
       "      <td> 0.863887</td>\n",
       "      <td>  260144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65545</th>\n",
       "      <td> 000b41258d624ef2d6e430822d0c0c8f</td>\n",
       "      <td> 0.992772</td>\n",
       "      <td>  590824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file_name   entropy  file_size\n",
       "0      00002e640cafb741bea9a48eaee27d6f  0.992174     208860\n",
       "1      000118d12cbf9ad6103e8b914a6e1ac3  0.834382     201600\n",
       "2      0001776237ac37a69fcef93c1bac0988  0.966021     682192\n",
       "65536  00027c21667d9119a454df8cef2dc1c7  0.666599      18390\n",
       "65537  0003887ab64b8ae19ffa988638decac2  0.903260    1134320\n",
       "3      000403e4e488356b7535cc613fbeb80b  0.773787     199168\n",
       "65538  0004376a62e22f6ad359467eb742b8ff  0.803515     149720\n",
       "4      0004c8b2a0f4680a5694d74199b40ea2  0.985592    1165440\n",
       "5      000595d8b586915c12053104cf845097  0.841920     264240\n",
       "65539  000634f03457d088c71dbffb897b1315  0.957584    1725502\n",
       "65540  00072ed24314e91b63b425b3dc572f50  0.486112     328093\n",
       "65541  00092d369958b67557da8661cc9093bc  0.845657     522936\n",
       "6      00093d5fa5cb7ce77f6eaf39962daa12  0.803481     742064\n",
       "7      00099926d51b44c6f8c93a48c2567891  0.997032     725288\n",
       "65542  0009a64f786fa29bfa6423278cc74f02  0.996663     671280\n",
       "8      000a2db4762dc06628a086c9e117f884  0.535436      61551\n",
       "65543  000ac11fa7587b2316470b154254a219  0.997824    1874471\n",
       "9      000ae2c63ba69fc93dfc395b40bfe03a  0.899481     487386\n",
       "65544  000ae90736a51c47543dcc6d8a735362  0.863887     260144\n",
       "65545  000b41258d624ef2d6e430822d0c0c8f  0.992772     590824\n",
       "\n",
       "[20 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropys = pd.read_csv('data/sorted-entropy-features.csv')\n",
    "sorted_entropys = entropys.sort('file_name')\n",
    "sorted_entropys.to_csv('data/sorted-entropy-features-vs251-252.csv', index=False)\n",
    "sorted_entropys.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Entropy and File Size of Unpacked Binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate PE ASM and Header Features\n",
    "    - PE Header Features from objdump header summaries.\n",
    "    - ASM Features from IDA Pro assembly files.\n",
    "    \n",
    "    - Script: feature_extraction_pe_asm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = ['Virtual','Offset','loc','Import','Imports','var','Forwarder','UINT','LONG'\n",
    "            ,'BOOL','WORD','BYTES','large','short','dd','db','dw','XREF','ptr','DATA'\n",
    "            ,'FUNCTION','extrn','byte','word','dword','char','DWORD','stdcall','arg'\n",
    "            ,'locret','asc','align','WinMain','unk','cookie','off','nullsub','DllEntryPoint'\n",
    "            ,'System32','dll','CHUNK','BASS','HMENU','DLL','LPWSTR','void','HRESULT','HDC'\n",
    "            ,'LRESULT','HANDLE','HWND','LPSTR','int','HLOCAL','FARPROC','ATOM','HMODULE'\n",
    "            ,'WPARAM','HGLOBAL','entry','rva','COLLAPSED','config','exe','Software'\n",
    "            ,'CurrentVersion','__imp_','INT_PTR','UINT_PTR','---Seperator','PCCTL_CONTEXT'\n",
    "            ,'__IMPORT_','INTERNET_STATUS_CALLBACK','.rdata:','.data:','.text:','case'\n",
    "            ,'installdir','market','microsoft','policies','proc','scrollwindow','search'\n",
    "            ,'trap','visualc','___security_cookie','assume','callvirtualalloc','exportedentry'\n",
    "            ,'hardware','hkey_current_user','hkey_local_machine','sp-analysisfailed','unableto']\n",
    "\n",
    "known_sections = ['.text', '.data', '.bss', '.rdata', '.edata', '.idata', '.rsrc', '.tls', '.reloc']\n",
    "\n",
    "registers = ['edx','esi','es','fs','ds','ss','gs','cs','ah','al',\n",
    "                 'ax','bh','bl','bx','ch','cl','cx','dh','dl','dx',\n",
    "                 'eax','ebp','ebx','ecx','edi','esp']\n",
    "\n",
    "opcodes = ['add','al','bt','call','cdq','cld','cli','cmc','cmp','const','cwd','daa','db'\n",
    "                ,'dd','dec','dw','endp','ends','faddp','fchs','fdiv','fdivp','fdivr','fild'\n",
    "                ,'fistp','fld','fstcw','fstcwimul','fstp','fword','fxch','imul','in','inc'\n",
    "                ,'ins','int','jb','je','jg','jge','jl','jmp','jnb','jno','jnz','jo','jz'\n",
    "                ,'lea','loope','mov','movzx','mul','near','neg','not','or','out','outs'\n",
    "                ,'pop','popf','proc','push','pushf','rcl','rcr','rdtsc','rep','ret','retn'\n",
    "                ,'rol','ror','sal','sar','sbb','scas','setb','setle','setnle','setnz'\n",
    "                ,'setz','shl','shld','shr','sidt','stc','std','sti','stos','sub','test'\n",
    "                ,'wait','xchg','xor']\n",
    "\n",
    "\n",
    "def count_asm_symbols(asm_code):\n",
    "    symbols = [0]*7\n",
    "    for row in asm_code:\n",
    "        if '*' in row:\n",
    "            symbols[0] += 1\n",
    "        if '-' in row:\n",
    "            symbols[1] += 1\n",
    "        if '+' in row:\n",
    "            symbols[2] += 1\n",
    "        if '[' in row:\n",
    "            symbols[3] += 1\n",
    "        if ']' in row:\n",
    "            symbols[4] += 1\n",
    "        if '@' in row:\n",
    "            symbols[5] += 1\n",
    "        if '?' in row:\n",
    "            symbols[6] += 1\n",
    "\n",
    "    return symbols\n",
    "\n",
    "\n",
    "def count_asm_registers(asm_code):\n",
    "    registers_values = [0]*len(registers)\n",
    "    for row in asm_code:\n",
    "        parts = row.replace(',',' ').replace('+',' ').replace('*',' ').replace('[',' ').replace(']',' ') \\\n",
    "                    .replace('-',' ').split()\n",
    "        for register in registers:\n",
    "            registers_values[registers.index(register)] += parts.count(register)\n",
    "    return registers_values\n",
    "\n",
    "\n",
    "def count_asm_opcodes(asm_code):\n",
    "    opcodes_values = [0]*len(opcodes)\n",
    "    for row in asm_code:\n",
    "        parts = row.split()\n",
    "\n",
    "        for opcode in opcodes:\n",
    "            if opcode in parts:\n",
    "                opcodes_values[opcodes.index(opcode)] += 1\n",
    "                break\n",
    "    return opcodes_values\n",
    "\n",
    "\n",
    "def count_asm_APIs(asm_code, apis):\n",
    "    apis_values = [0]*len(apis)\n",
    "    for row in asm_code:\n",
    "        for i in range(len(apis)):\n",
    "            if apis[i] in row:\n",
    "                apis_values[i] += 1\n",
    "                break\n",
    "    return apis_values\n",
    "\n",
    "\n",
    "def count_asm_misc(asm_code):\n",
    "    keywords_values = [0]*len(keywords)\n",
    "    for row in asm_code:\n",
    "        for i in range(len(keywords)):\n",
    "            if keywords[i] in row:\n",
    "                keywords_values[i] += 1\n",
    "                break\n",
    "    return keywords_values\n",
    "\n",
    "\n",
    "# Extract features from test/training asm files, file list is passed in as a parameter\n",
    "\n",
    "def extract_asm_features(tfiles):\n",
    "    \n",
    "    pid = os.getpid()\n",
    "    print('Process id:', pid)\n",
    "    feature_file = 'data/' + str(pid) + '-malware-features-asm.csv' # Windows API, symbols, registers, opcodes, etc...   \n",
    "    print('feature file:', feature_file)\n",
    "\n",
    "    fapi = open(\"data/APIs.txt\")\n",
    "    defined_apis = fapi.readlines()\n",
    "    defined_apis = defined_apis[0].split(',')\n",
    "\n",
    "    asm_files = [i for i in tfiles if '.asm' in i]\n",
    "    ftot = len(asm_files)\n",
    "    \n",
    "    feature_counts = []\n",
    "    with open(feature_file, 'w') as f:\n",
    "        # write the csv header\n",
    "        fw = writer(f)\n",
    "        colnames = ['file_name'] + registers + opcodes + defined_apis + keywords\n",
    "        fw.writerow(colnames)\n",
    "        \n",
    "        for idx, fname in enumerate(asm_files):\n",
    "            fasm = open(ext_drive + fname, 'r')\n",
    "            content = fasm.readlines()\n",
    "            \n",
    "            reg_vals = count_asm_registers(content)\n",
    "            opc_vals = count_asm_opcodes(content)\n",
    "            api_vals = count_asm_APIs(content, defined_apis)\n",
    "            #sec_vals = count_asm_sections(content)\n",
    "            mis_vals = count_asm_misc(content)\n",
    "            count_vals = reg_vals + opc_vals + api_vals + mis_vals\n",
    "            \n",
    "            feature_counts.append([fname[:fname.find('.asm')]] + count_vals)   \n",
    "            \n",
    "            # Writing rows after every 10 files processed\n",
    "            if (idx+1) % 10 == 0:\n",
    "              print(pid, idx + 1, 'of', ftot, 'files processed.')\n",
    "              fw.writerows(feature_counts)\n",
    "              feature_counts = []\n",
    "                \n",
    "        # Writing remaining files\n",
    "        if len(feature_counts) > 0:\n",
    "            fw.writerows(feature_counts)\n",
    "            feature_counts = []\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Clean and Sort Function Names\n",
    "    - script: function_name_clean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to clean up and sort these function names for ASM feature extraction.\n",
    "fip = open('data/all-function-column-names-multiline.csv')\n",
    "function_names = fip.readlines()\n",
    "fip.close()\n",
    "\n",
    "function_names.sort()\n",
    "function_names[:50]\n",
    "\n",
    "fop = open('data/sorted-function-names-multiline.txt','w')\n",
    "fop.writelines(function_names)\n",
    "fop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fip = open('data/sorted-function-names-multiline.txt','r')\n",
    "sorted_function_names = fip.readlines()\n",
    "fip.close()\n",
    "fip = open('data/APIs.txt','r')\n",
    "api_names_str = fip.readline()\n",
    "fip.close()\n",
    "api_names_str = api_names_str.rstrip()\n",
    "api_names = api_names_str.split(',')\n",
    "api_names.sort()\n",
    "len(api_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155548"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx in range(len(sorted_function_names)):\n",
    "    sorted_function_names[idx] = sorted_function_names[idx].rstrip()\n",
    "    \n",
    "for aname in api_names:\n",
    "    if aname not in sorted_function_names:\n",
    "        sorted_function_names.append(aname)\n",
    "        \n",
    "sorted_function_names.sort()\n",
    "len(sorted_function_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_function_names[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_count = len(sorted_function_names)\n",
    "total_chars = 0\n",
    "for func_name in sorted_function_names:\n",
    "    total_chars += len(func_name)\n",
    "    \n",
    "avg_name_len = int(total_chars / function_count)\n",
    "avg_name_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# truncate function names to reduce the size of the huge sparse matrix.\n",
    "function_column_names = []\n",
    "for func in sorted_function_names:\n",
    "    if func.startswith('sub') or func.startswith('loc') or func.startswith('unk'):\n",
    "        func = func[:5] # lets try to reduce the vast number of functions.\n",
    "    elif func.startswith('eax+') or func.startswith('ebx+') or func.startswith('ecx+') or func.startswith('edx+'):\n",
    "        func = func[:3]\n",
    "    elif func.startswith('edi+') or func.startswith('esi+'):\n",
    "        func = func[:3]\n",
    "    elif func.startswith('byte_') or func.startswith('word_') or func.startswith('off_'):\n",
    "        func = func[:4]\n",
    "    elif func.startswith('_') or func.startswith('$'):\n",
    "        func = func[1:]\n",
    "    elif func.startswith('__') or func.startswith('$$'):\n",
    "        func = func[2:]\n",
    "    #else: need a regex here to match a bunch of random crap \n",
    "    #    func = func[:33]\n",
    "        \n",
    "    if len(func) > 32: # Reduce the the function name length to max of average function length.\n",
    "        func = func[:32]\n",
    "        \n",
    "    if func not in function_column_names:    \n",
    "        function_column_names.append(func)\n",
    "        \n",
    "function_column_names[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143048"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fop = open('data/sorted-reduced-function-names.txt','w')\n",
    "\n",
    "for fname in function_column_names:\n",
    "    fop.write(fname + \"\\n\")\n",
    "        \n",
    "fop.close()\n",
    "\n",
    "len(function_column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use a regex to remove function names that are just hexadecimal addresses.\n",
    "p1 = re.compile('\\d\\w+h')\n",
    "reduced_function_names = []\n",
    "fip = open('data/sorted-reduced-function-names.txt','r')\n",
    "function_column_names = fip.readlines()\n",
    "fip.close()\n",
    "\n",
    "fop = open('data/sorted-reduced-function-names-hexless.txt','w')\n",
    "for fname in function_column_names:\n",
    "    fname = fname.rstrip()\n",
    "    m = p1.match(fname)\n",
    "    if m == None:\n",
    "        fop.write(fname + \"\\n\")\n",
    "        reduced_function_names.append(fname)\n",
    "        \n",
    "fop.close()\n",
    "reduced_function_names[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135436"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reduced_function_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Code Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signat = sub.check_output([\"file\",'-b', '/opt/vs/agobot.exe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PE32 executable (GUI) Intel 80386, for MS Windows, UPX compressed\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate libc function calls for ELF API feature extraction.\n",
    "# Put in feature_extraction_elf_asm.py\n",
    "\n",
    "def generate_libc_api():\n",
    "    # Extract libc function and variable names from GNU Libc Documentation.\n",
    "    # Put in feature_extraction.py\n",
    "    \n",
    "    fipfunc = open('data/libc-function-index.txt', 'r')\n",
    "    funclines = fipfunc.readlines()\n",
    "    fipfunc.close()\n",
    "    \n",
    "    counter = 0\n",
    "    func_list = []\n",
    "    \n",
    "    for idx, fline in enumerate(funclines):\n",
    "        fline = fline.replace('\\t','').replace('\\n','')\n",
    "        if fline.startswith('|'):\n",
    "            tokens = fline.split('|')   # The function names are |funcname|\n",
    "            funcname = tokens[1]\n",
    "            func_list.append(funcname)\n",
    "            counter += 1\n",
    "            \n",
    "            \n",
    "    print(\"Found {:d} function definitions for libc api.\".format(counter))\n",
    "    \n",
    "    fop = open('data/elf-libc-api.txt', 'w')\n",
    "    \n",
    "    for func_name in func_list:\n",
    "        fop.write(func_name + \"\\n\")\n",
    "        \n",
    "    fop.close()\n",
    "    \n",
    "    return func_list\n",
    "\n",
    "\n",
    "def generate_libc_var():\n",
    "    # Extract libc function and variable names from GNU Libc Documentation.\n",
    "    # Put in feature_extraction.py\n",
    "\n",
    "    fipvar = open('data/libc-variable-index.txt', 'r')\n",
    "    varlines = fipvar.readlines()\n",
    "    fipvar.close()\n",
    "    \n",
    "    counter = 0\n",
    "    var_list = []\n",
    "    \n",
    "    for idx, vline in enumerate(varlines):\n",
    "        vline = vline.replace('\\t','').replace('\\n','')\n",
    "        if vline.startswith('|'):\n",
    "            tokens = vline.split('|')   # The function names are |funcname|\n",
    "            varname = tokens[1]\n",
    "            var_list.append(varname)\n",
    "            counter += 1\n",
    "            \n",
    "            \n",
    "    print(\"Found {:d} variable definitions for libc api.\".format(counter))\n",
    "    \n",
    "    fop = open('data/elf-libc-var.txt', 'w')\n",
    "    \n",
    "    for var_name in var_list:\n",
    "        fop.write(var_name + \"\\n\")\n",
    "        \n",
    "    fop.close()\n",
    "    \n",
    "    return var_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "func_list = generate_libc_api()\n",
    "func_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asm dir: 21314 asm files 21314 hdr dir 21409 hdr files 21409\n"
     ]
    }
   ],
   "source": [
    "# Check interrupted disassembly results for train1 feature set.\n",
    "# def validate_disassembly():\n",
    "# put in disassemble_pe.py\n",
    "\n",
    "t1asm = os.listdir('/opt/vs/train1asm/')\n",
    "t1hdr = os.listdir('/opt/vs/train1hdr/')\n",
    "asm_files = []\n",
    "hdr_files = []\n",
    "\n",
    "for fname in t1asm:\n",
    "    if fname.endswith('.asm'):\n",
    "        asm_files.append(fname)\n",
    "        \n",
    "for fname in t1hdr:\n",
    "    if fname.endswith('.txt'):\n",
    "        hdr_files.append(fname)\n",
    "        \n",
    "        \n",
    "print(\"asm dir: {:d} asm files {:d} hdr dir {:d} hdr files {:d}\".format(len(t1asm),len(asm_files),len(t1hdr),len(hdr_files)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t1hdr) - len(t1asm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77814888"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize('/opt/vs/train1asm/VirusShare_5ac1817d757a27edb90cdf887ba66870.asm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 missing header files.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "missing_hdr_list = []\n",
    "\n",
    "for fname in asm_files:\n",
    "    hdr_name = fname.replace('.asm', '.txt')\n",
    "    if hdr_name not in hdr_files:\n",
    "        print(\"{:s} not in header file list.\".format(hdr_name))\n",
    "        counter += 1\n",
    "        missing_asm_list.append(fname)\n",
    "        \n",
    "print(\"{:d} missing header files.\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "missing_asm_list = []\n",
    "\n",
    "for fname in hdr_files:\n",
    "    asm_name = fname.replace('.txt','.asm')\n",
    "    if asm_name not in asm_files:\n",
    "        print(\"{:s} not in asm file list.\".format(asm_name))\n",
    "        counter += 1\n",
    "        missing_asm_list.append(fname)\n",
    "        \n",
    "print(\"{:d} missing assembly files.\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 95 missing asm file names.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "fop = open('data/disass-train1-missing-asm-files.txt', 'w')\n",
    "for fname in missing_asm_list:\n",
    "    fop.write(fname + \"\\n\")\n",
    "    counter += 1\n",
    "        \n",
    "fop.close()\n",
    "print(\"Wrote {:d} missing asm file names.\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VirusShare_d5eff38b212286c46db007aa7159ffd8.txt bad output, filesize = 0.\n",
      "VirusShare_592d7ac775519110d58e9ce1975c1b5b.txt bad output, filesize = 0.\n",
      "VirusShare_4a0c79f6ad27b0a674b08005d102e16d.txt bad output, filesize = 0.\n",
      "VirusShare_c80d9b2dbf9b7953a3b6e9b51a39a0c2.txt bad output, filesize = 0.\n",
      "4 bad header files.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "bad_hdr_list = []\n",
    "\n",
    "for fname in hdr_files:\n",
    "    fsize = os.path.getsize('/opt/vs/train1hdr/' + fname)\n",
    "    if fsize < 1000:\n",
    "        print(\"{:s} bad output, filesize = {:d}.\".format(fname, fsize))\n",
    "        counter += 1\n",
    "        bad_hdr_list.append(fname)\n",
    "        \n",
    "print(\"{:d} bad header files.\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "bad_asm_list = []\n",
    "\n",
    "for fname in asm_files:\n",
    "    fsize = os.path.getsize('/opt/vs/train1asm/' + fname)\n",
    "    if fsize < 1000:\n",
    "        print(\"{:s} bad output, filesize = {:d}.\".format(fname, fsize))\n",
    "        counter += 1\n",
    "        bad_asm_list.append(fname)\n",
    "        \n",
    "print(\"{:d} bad asm files.\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apt_df = pd.read_csv('data/sorted-entropy-features-apt.csv')\n",
    "apt_file_list = apt_df['file_name']\n",
    "apt_file_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    001dd76872d80801692ff942308c64e6\n",
       "1    002325a0a67fded0381b5648d7fe9b8e\n",
       "2    00dbb9e1c09dbdafb360f3163ba5a3de\n",
       "3    0149b7bd7218aab4e257d28469fddb0d\n",
       "4    01e0dc079d4e33d8edd050c4900818da\n",
       "Name: file_name, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apt_file_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 294 files in training directory.\n",
      "Extra file: 00248ef21706d78c1f0e1eca3cab72c3\n"
     ]
    }
   ],
   "source": [
    "f_list = os.listdir('/home/derek/project/temp/train/')\n",
    "counter = 0\n",
    "file_list = []\n",
    "for fname in f_list:\n",
    "    if fname.startswith('Virus'):\n",
    "        tname = fname[fname.find('_') + 1:]\n",
    "        file_list.append(tname)\n",
    "        counter += 1\n",
    "        \n",
    "print(\"Got {:d} files in training directory.\".format(counter))\n",
    "\n",
    "apt_list = np.array(apt_file_list)\n",
    "for fname in file_list:\n",
    "    if fname not in apt_list:\n",
    "        print(\"Extra file: {:s}\".format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rename_header_files(ext_dir):\n",
    "    # Rename all the PE headers files so it is easier to process them.\n",
    "    \n",
    "    file_list = os.listdir(ext_dir)\n",
    "    counter = 0\n",
    "    \n",
    "    for fname in file_list:\n",
    "        if fname.startswith('Virus'):\n",
    "            file_path = ext_dir + fname\n",
    "            trunc_name = fname[0:fname.find('.txt')]\n",
    "            new_path = ext_dir + trunc_name + '.pe.txt'\n",
    "            result = sub.check_call(['mv', file_path, new_path])\n",
    "            counter += 1\n",
    "\n",
    "        if (counter % 1000) == 0:\n",
    "            print('Renamed {:d} header files.'.format(counter))\n",
    "\n",
    "    print('Completed move of {:d} header files.'.format(counter))\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ext_dir = '/home/derek/project/temp/'\n",
    "rename_header_files(ext_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename_asm_files(ext_dir):\n",
    "    # Rename all the PE headers files so it is easier to process them.\n",
    "    \n",
    "    file_list = os.listdir(ext_dir)\n",
    "    counter = 0\n",
    "    \n",
    "    for fname in file_list:\n",
    "        if fname.endswith('.asm'):\n",
    "            file_path = ext_dir + fname\n",
    "            trunc_name = fname[0:fname.find('.asm')]\n",
    "            new_path = ext_dir + trunc_name + '.pe.asm'\n",
    "            result = sub.check_call(['mv', file_path, new_path])\n",
    "            counter += 1\n",
    "\n",
    "            if (counter % 1000) == 0:\n",
    "                print('Renamed {:d} ASM files.'.format(counter))\n",
    "\n",
    "    print('Completed move of {:d} ASM files.'.format(counter))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rename_asm_files('/opt/vs/train1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename_asm_files_fix_train1asm(ext_dir):\n",
    "    # Rename all the PE headers files so it is easier to process them.\n",
    "    \n",
    "    file_list = os.listdir(ext_dir)\n",
    "    pe_counter = 0\n",
    "    unpe_counter = 0\n",
    "    \n",
    "    print(\"Got total files: {:d}\".format(len(file_list)))\n",
    "    \n",
    "    for fname in file_list:\n",
    "        if fname.endswith('.pe.asm'):\n",
    "            pe_counter += 1\n",
    "        else:\n",
    "            file_path = ext_dir + fname\n",
    "            trunc_name = fname[0:fname.find('.asm')]\n",
    "            new_path = ext_dir + trunc_name + '.pe.asm'\n",
    "            result = sub.check_call(['mv', file_path, new_path])\n",
    "            unpe_counter += 1\n",
    "\n",
    "            if (unpe_counter % 1000) == 0:\n",
    "                print('Renamed {:d} ASM files.'.format(unpe_counter))\n",
    "\n",
    "    print('Completed move of {:d} ASM files with {:d} files already renamed.'.format(unpe_counter, pe_counter))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rename_asm_files_fix_train1asm('/opt/vs/train1asm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_disassembly(asm_path, hdr_path): \n",
    "    # Check disassembly results for the malware set.\n",
    "    # TODO: move header and asm files to the corresponding directories.\n",
    "\n",
    "    t1asm = os.listdir(asm_path)\n",
    "    t1hdr = os.listdir(hdr_path)\n",
    "    asm_files = []\n",
    "    hdr_files = []\n",
    "\n",
    "    for fname in t1asm:\n",
    "        if fname.endswith('.pe.asm'):\n",
    "            asm_files.append(fname)\n",
    "\n",
    "    for fname in t1hdr:\n",
    "        if fname.endswith('.pe.txt'):\n",
    "            hdr_files.append(fname)\n",
    "\n",
    "    print(\"asm dir: {:d} asm files {:d} hdr dir {:d} hdr files {:d}\".format(len(t1asm),len(asm_files),len(t1hdr),len(hdr_files)))\n",
    "    \n",
    "    counter = 0\n",
    "    missing_hdr_list = []\n",
    "\n",
    "    for fname in asm_files:\n",
    "        hdr_name = fname.replace('.asm', '.txt')\n",
    "        if hdr_name not in hdr_files:\n",
    "            print(\"{:s} not in header file list.\".format(hdr_name))\n",
    "            counter += 1\n",
    "            missing_hdr_list.append(hdr_name)\n",
    "\n",
    "    print(\"{:d} missing header files.\".format(counter))\n",
    " \n",
    "    counter = 0\n",
    "    missing_asm_list = []\n",
    "\n",
    "    for fname in hdr_files:\n",
    "        asm_name = fname.replace('.txt','.asm')\n",
    "        if asm_name not in asm_files:\n",
    "            print(\"{:s} not in asm file list.\".format(asm_name))\n",
    "            counter += 1\n",
    "            missing_asm_list.append(asm_name)\n",
    "\n",
    "    print(\"{:d} missing assembly files.\".format(counter))\n",
    "\n",
    "    if len(missing_asm_list) > 0:\n",
    "        counter = 0\n",
    "        fop = open('data/temp-disass-missing-asm-files.txt', 'w')\n",
    "        for fname in missing_asm_list:\n",
    "            fop.write(fname + \"\\n\")\n",
    "            counter += 1\n",
    "\n",
    "        fop.close()\n",
    "        print(\"Wrote {:d} missing asm file names.\".format(counter))\n",
    "\n",
    "    if len(missing_hdr_list) > 0:\n",
    "        counter = 0\n",
    "        fop = open('data/temp-disass-missing-hdr-files.txt', 'w')\n",
    "        for fname in missing_hdr_list:\n",
    "            fop.write(fname + \"\\n\")\n",
    "            counter += 1\n",
    "\n",
    "        fop.close()\n",
    "        print(\"Wrote {:d} missing hdr file names.\".format(counter))\n",
    "        \n",
    "    counter = 0\n",
    "    bad_asm_list = []\n",
    "\n",
    "    for fname in asm_files:\n",
    "        fsize = os.path.getsize(asm_path + fname)\n",
    "        if fsize < 1000:\n",
    "            print(\"{:s} bad output, filesize = {:d}.\".format(fname, fsize))\n",
    "            counter += 1\n",
    "            bad_asm_list.append(fname)\n",
    "\n",
    "    print(\"{:d} bad asm files.\".format(counter))\n",
    "\n",
    "    counter = 0\n",
    "    bad_hdr_list = []\n",
    "\n",
    "    for fname in hdr_files:\n",
    "        fsize = os.path.getsize(hdr_path + fname)\n",
    "        if fsize < 1000:\n",
    "            print(\"{:s} bad output, filesize = {:d}.\".format(fname, fsize))\n",
    "            counter += 1\n",
    "            bad_hdr_list.append(fname)\n",
    "\n",
    "    print(\"{:d} bad header files.\".format(counter))\n",
    "\n",
    "    if len(bad_hdr_list) > 0:\n",
    "        counter = 0\n",
    "        fop = open('data/temp-disass-bad-hdr-files.txt', 'w')\n",
    "        for fname in bad_hdr_list:\n",
    "            fop.write(fname + \"\\n\")\n",
    "            counter += 1\n",
    "\n",
    "        fop.close()\n",
    "        \n",
    "    print(\"Wrote {:d} bad hdr file names.\".format(counter))\n",
    "\n",
    "    if len(bad_asm_list) > 0:\n",
    "        counter = 0\n",
    "        fop = open('data/temp-disass-bad-asm-files.txt', 'w')\n",
    "        for fname in bad_asm_list:\n",
    "            fop.write(fname + \"\\n\")\n",
    "            counter += 1\n",
    "\n",
    "        fop.close()\n",
    "        \n",
    "    print(\"Wrote {:d} bad asm file names.\".format(counter))\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asm dir: 54911 asm files 54911 hdr dir 55128 hdr files 55128\n",
      "0 missing header files.\n",
      "VirusShare_40e82a9664a9f6013eb6f583ac2aab72.pe.asm not in asm file list.\n",
      "VirusShare_dbbc7898d662a1ec9452a91f630075dc.pe.asm not in asm file list.\n",
      "VirusShare_5be094c346e3dbf209bdf736cb6dfdd4.pe.asm not in asm file list.\n",
      "VirusShare_f1270aafe666817b84812dd1a0108dbc.pe.asm not in asm file list.\n",
      "VirusShare_006b4c72e79e60d10515a64ec6a4e021.pe.asm not in asm file list.\n",
      "VirusShare_3bfd708d47c55b4c0c68c98a3c725e57.pe.asm not in asm file list.\n",
      "VirusShare_f2833230de754994532a9f6ab7df961f.pe.asm not in asm file list.\n",
      "VirusShare_b4efafc4cfc4705cf53ee88564e9613c.pe.asm not in asm file list.\n",
      "VirusShare_02b88fab6d6a76e3f00e99d88b42e29e.pe.asm not in asm file list.\n",
      "VirusShare_e4e20059da698c059eec5a4b9735d5e9.pe.asm not in asm file list.\n",
      "VirusShare_6f9412b1845253bd8060dad34df89078.pe.asm not in asm file list.\n",
      "VirusShare_c426fae580d263ead178b0fdddf2b43e.pe.asm not in asm file list.\n",
      "VirusShare_9b57adb5b64546b03005311813def67b.pe.asm not in asm file list.\n",
      "VirusShare_02e6357bc2e276c4113e6de1a5b1c69c.pe.asm not in asm file list.\n",
      "VirusShare_7c2bfb0e4843499aea1a73d0647807d6.pe.asm not in asm file list.\n",
      "VirusShare_42e96ba9d4d6848ce05e175a0c9d8ad6.pe.asm not in asm file list.\n",
      "VirusShare_9d6b57c9589203a27be85b146eb35395.pe.asm not in asm file list.\n",
      "VirusShare_f35ba2f551142e9cec2ccee7ba9b8025.pe.asm not in asm file list.\n",
      "VirusShare_af18862f770020dbfcc4450a00aa4a15.pe.asm not in asm file list.\n",
      "VirusShare_d4a981ca6fdd8a24a6881782bd8ab9ed.pe.asm not in asm file list.\n",
      "VirusShare_ecf0eba4db18be1193607e8579c72496.pe.asm not in asm file list.\n",
      "VirusShare_f3b0909bac775b574294f061cf94f871.pe.asm not in asm file list.\n",
      "VirusShare_ffd952280cc825b6382e2b27ed8462db.pe.asm not in asm file list.\n",
      "VirusShare_43ca59f4c0603b0a6eeb403a07f4f998.pe.asm not in asm file list.\n",
      "VirusShare_58ccac83885dc6d62c00309cf54b8919.pe.asm not in asm file list.\n",
      "VirusShare_90076fd598913418fccfeb4f82590d04.pe.asm not in asm file list.\n",
      "VirusShare_af9292aadba986eb25ce696fc4c24846.pe.asm not in asm file list.\n",
      "VirusShare_a7a8f5661fd76ddf1b448e4120b2d509.pe.asm not in asm file list.\n",
      "VirusShare_47e28f7e7c2ccea3cec30091f76812cc.pe.asm not in asm file list.\n",
      "VirusShare_19e54e8043c223f7fec829b8fbe3c426.pe.asm not in asm file list.\n",
      "VirusShare_761d967ddadcf3c043578ec5782d8f2e.pe.asm not in asm file list.\n",
      "VirusShare_f49945628d57a1290f68c17294873fcd.pe.asm not in asm file list.\n",
      "VirusShare_04a67827c0152aafdad6caa34f5a9ac0.pe.asm not in asm file list.\n",
      "VirusShare_0e89e46060a34d1c2b90ee8e281d26b8.pe.asm not in asm file list.\n",
      "VirusShare_852c2d4072c4d7259b669e08dbc5561e.pe.asm not in asm file list.\n",
      "VirusShare_a539705e0ab6c3ad8edf187e452f7c6a.pe.asm not in asm file list.\n",
      "VirusShare_1fb9635b03334fea9779f1190f19dcbe.pe.asm not in asm file list.\n",
      "VirusShare_f002546f1ad39faa73bd3782f6ea516e.pe.asm not in asm file list.\n",
      "VirusShare_93cae43473a128f65f8c11c34becd6d8.pe.asm not in asm file list.\n",
      "VirusShare_5042385fa5fb51243a7031ccf08c0313.pe.asm not in asm file list.\n",
      "VirusShare_243387362454a5f2d18e060f47b23cd1.pe.asm not in asm file list.\n",
      "VirusShare_bf6f53c75790081ed5a6da43f068418f.pe.asm not in asm file list.\n",
      "VirusShare_f21354590388e1dd8d3b20380c517913.pe.asm not in asm file list.\n",
      "VirusShare_4323c316eb8fb7377e9cb9ffb6a17ae2.pe.asm not in asm file list.\n",
      "VirusShare_20e9b4d3e0f569cb2ae2f9f87342e51d.pe.asm not in asm file list.\n",
      "VirusShare_46ffaf405f818c47b212869e741feded.pe.asm not in asm file list.\n",
      "VirusShare_35338f5a2a717aae0841d961084dbb07.pe.asm not in asm file list.\n",
      "VirusShare_ced53b3806b9daf5390f4e6f36173c35.pe.asm not in asm file list.\n",
      "VirusShare_dcda37af9a8f546e304a9a2624fe7760.pe.asm not in asm file list.\n",
      "VirusShare_901db5f3e4db5e628290d1295ae2b703.pe.asm not in asm file list.\n",
      "VirusShare_43148dd112bcd2c583695ffeb72933d1.pe.asm not in asm file list.\n",
      "VirusShare_0617574026f829981e8ceb90186102f4.pe.asm not in asm file list.\n",
      "VirusShare_30589eb7e7421977a50977feefbe89b6.pe.asm not in asm file list.\n",
      "VirusShare_787d3645c5b5393984e7557daa389249.pe.asm not in asm file list.\n",
      "VirusShare_e8ab8e026fc047192d8f1e05377b45e5.pe.asm not in asm file list.\n",
      "VirusShare_1d537fc1cd74f6f768a642cd257b21ae.pe.asm not in asm file list.\n",
      "VirusShare_aee349c030b46fbfd311c012f9138b77.pe.asm not in asm file list.\n",
      "VirusShare_da1c29ce19babf2144d450ec66689fa9.pe.asm not in asm file list.\n",
      "VirusShare_f3b0f6e634f683be6ff94e200c772c04.pe.asm not in asm file list.\n",
      "VirusShare_cdca843ab18ca795cf9e917b7ee72e3f.pe.asm not in asm file list.\n",
      "VirusShare_f0b373bb2cd5fd2c22342866cdb492ea.pe.asm not in asm file list.\n",
      "VirusShare_378d5c7ef8e359b5185441cbe815b22e.pe.asm not in asm file list.\n",
      "VirusShare_b6ebfc3695404e1909ac24aa14446dc8.pe.asm not in asm file list.\n",
      "VirusShare_a6bbbcb1ec1b5786fdf4b6cddb672605.pe.asm not in asm file list.\n",
      "VirusShare_13f7d8b3a990b0c7f202d78df538c9bb.pe.asm not in asm file list.\n",
      "VirusShare_4ace3636facb1c6c403ce94880e5a3f1.pe.asm not in asm file list.\n",
      "VirusShare_40d0a73c2bbbef10f693a7e2ee5ed031.pe.asm not in asm file list.\n",
      "VirusShare_4d130b392ac11b31237b44eb809bd5c2.pe.asm not in asm file list.\n",
      "VirusShare_3f290a1d2155b9c27adba9900200dff1.pe.asm not in asm file list.\n",
      "VirusShare_aef5f026bb9d5c239327b92d36710281.pe.asm not in asm file list.\n",
      "VirusShare_36cb828738111e0580a28607c713fcc7.pe.asm not in asm file list.\n",
      "VirusShare_ebfadd490637685321dd496315779b20.pe.asm not in asm file list.\n",
      "VirusShare_01561d7971d10d2192e87b75a74980a4.pe.asm not in asm file list.\n",
      "VirusShare_1ced2adfe2f6eaf60de416367fcaafb8.pe.asm not in asm file list.\n",
      "VirusShare_592d7ac775519110d58e9ce1975c1b5b.pe.asm not in asm file list.\n",
      "VirusShare_2685fcdf736c1a10ace140c1a389c1a2.pe.asm not in asm file list.\n",
      "VirusShare_5cb37ab9dd3b655ee8a8fa724cc0ab95.pe.asm not in asm file list.\n",
      "VirusShare_e6d36362f2a06ef9284c0535543f546e.pe.asm not in asm file list.\n",
      "VirusShare_36e769d7677372ff39a2201d14f1a0ae.pe.asm not in asm file list.\n",
      "VirusShare_bc6d5f46e18ab817f1d9a429475ea043.pe.asm not in asm file list.\n",
      "VirusShare_4585ecd431ac31f689edffbe821222ed.pe.asm not in asm file list.\n",
      "VirusShare_11b606eb450b7ffa40200e3bfcb13955.pe.asm not in asm file list.\n",
      "VirusShare_f41bb1a2dd155978eccccb0c88d6dbb0.pe.asm not in asm file list.\n",
      "VirusShare_2ff8d5f82c01ccbf41900209c5e3ef45.pe.asm not in asm file list.\n",
      "VirusShare_d68c467d5d9f6fea9d44e6271139eebd.pe.asm not in asm file list.\n",
      "VirusShare_87269df4344e923bae3362951f4d9c79.pe.asm not in asm file list.\n",
      "VirusShare_0d416bef3492f7b059a17975a31b5b82.pe.asm not in asm file list.\n",
      "VirusShare_57b17ff06400646d36702d96d7507737.pe.asm not in asm file list.\n",
      "VirusShare_9c9f9ac3787e3294a9edfb41b308cd11.pe.asm not in asm file list.\n",
      "VirusShare_139ae2c62d3bce016412782d98ad0088.pe.asm not in asm file list.\n",
      "VirusShare_3353582be8b58f9522f35caecd400542.pe.asm not in asm file list.\n",
      "VirusShare_018c4ec104af60efebd868c6c96c4015.pe.asm not in asm file list.\n",
      "VirusShare_f3d2c5874725460ec2d18326a259daac.pe.asm not in asm file list.\n",
      "VirusShare_f333e6e4c4332015ac26d000ed41d9c6.pe.asm not in asm file list.\n",
      "VirusShare_178ee5afe57dc4cb4300d21ace58530b.pe.asm not in asm file list.\n",
      "VirusShare_9585d9a2a70d0136e75f0c95c63ba338.pe.asm not in asm file list.\n",
      "VirusShare_b91131566f7e9c3ad10c4d96c06eb81d.pe.asm not in asm file list.\n",
      "VirusShare_b521d35d14ba945029c1b84b13c564dd.pe.asm not in asm file list.\n",
      "VirusShare_f393c1ab8e244661380b8ca12b3e376b.pe.asm not in asm file list.\n",
      "VirusShare_91991a3ab0775fcbe838982691139180.pe.asm not in asm file list.\n",
      "VirusShare_f22088d5baa1c3215b88e6c110ff40b3.pe.asm not in asm file list.\n",
      "VirusShare_0e5ba81019f7e6f7c43ca66dc7ac5c16.pe.asm not in asm file list.\n",
      "VirusShare_187e68d3020e0b8e6b170ec3d9f8162f.pe.asm not in asm file list.\n",
      "VirusShare_44aee51b25410e4436b07247712eb4dc.pe.asm not in asm file list.\n",
      "VirusShare_a501da86c075c1a228ca3c5731219db4.pe.asm not in asm file list.\n",
      "VirusShare_1528d21509f44e226cde92a631c378ae.pe.asm not in asm file list.\n",
      "VirusShare_93cb3b4e6f04fabc2bb58de908ba10fd.pe.asm not in asm file list.\n",
      "VirusShare_0ec341c56c0904b9cf829d064cb4346b.pe.asm not in asm file list.\n",
      "VirusShare_ed9d5437cdbf968378c27fe62bde39db.pe.asm not in asm file list.\n",
      "VirusShare_02d15c11abb5ef375e9ac3e9f05a1a52.pe.asm not in asm file list.\n",
      "VirusShare_14073474351a3f9952353da5c4f8e5f5.pe.asm not in asm file list.\n",
      "VirusShare_bc6410cbf6122ff3fd076782eadd81d5.pe.asm not in asm file list.\n",
      "VirusShare_3ac9175db0692f99969b1f2cde449e0d.pe.asm not in asm file list.\n",
      "VirusShare_1b3e633181eeb113fedec9bf185e2aa2.pe.asm not in asm file list.\n",
      "VirusShare_a95b885ca29b2fcd9ab30cf363da8d2b.pe.asm not in asm file list.\n",
      "VirusShare_5198eed6535c08df7d6d49f16516de0f.pe.asm not in asm file list.\n",
      "VirusShare_a62a6e9aaba8b71a1a3eb6924046e83d.pe.asm not in asm file list.\n",
      "VirusShare_05d002e31b65cc487d26aeafef273177.pe.asm not in asm file list.\n",
      "VirusShare_9c268c4227e47bfb474fb7c0b73f7c6d.pe.asm not in asm file list.\n",
      "VirusShare_64f833ce6cd86f4840e91ceda0b6c107.pe.asm not in asm file list.\n",
      "VirusShare_3d2d35e9d2de6c8121d5efb1189eaf33.pe.asm not in asm file list.\n",
      "VirusShare_a2b75ab9fad58c1e2c4f5caf0f4bee8c.pe.asm not in asm file list.\n",
      "VirusShare_4e4899e47d643652eae5b1a0ce08607b.pe.asm not in asm file list.\n",
      "VirusShare_0a85286b7376d8bc3fd2f6a6d5eab40b.pe.asm not in asm file list.\n",
      "VirusShare_2204207424c792a8286d9ae22088c7d1.pe.asm not in asm file list.\n",
      "VirusShare_f006d9bc02a72f425a2e519e71bba898.pe.asm not in asm file list.\n",
      "VirusShare_c58e2ca4bc8460632d713b441b531982.pe.asm not in asm file list.\n",
      "VirusShare_15554b08b6ba2960e0292b2366c342f4.pe.asm not in asm file list.\n",
      "VirusShare_40b62308312e99ce5c6b91a4a32acaaa.pe.asm not in asm file list.\n",
      "VirusShare_f183c89d1f41a130093233cc0b26c9a9.pe.asm not in asm file list.\n",
      "VirusShare_f3d92b60dd2e5adc9ae06b3d37fc22e9.pe.asm not in asm file list.\n",
      "VirusShare_0b0df093be65c46a33e577db692ce7c5.pe.asm not in asm file list.\n",
      "VirusShare_f2ea096c9d88f2dba1ebcca7da367b23.pe.asm not in asm file list.\n",
      "VirusShare_038ae293c2dd804f41f7f7305f37ebe2.pe.asm not in asm file list.\n",
      "VirusShare_af6986d4e6084fb1fcd140c16b27f5f4.pe.asm not in asm file list.\n",
      "VirusShare_f1e28ab39561164dc8fb6ee022820b13.pe.asm not in asm file list.\n",
      "VirusShare_17b527724c75a1432ceda6eed3c8ff52.pe.asm not in asm file list.\n",
      "VirusShare_c8d61ebbf58ae67d0f1cc76e81643db5.pe.asm not in asm file list.\n",
      "VirusShare_f06b8081a2b3c8e385739c83cf7f15ce.pe.asm not in asm file list.\n",
      "VirusShare_33866aa387e0b0af781604d4722ec94a.pe.asm not in asm file list.\n",
      "VirusShare_48745198d9b41861f56771d6791ab12e.pe.asm not in asm file list.\n",
      "VirusShare_556f88c007fbd965692ad4f2ba73aa88.pe.asm not in asm file list.\n",
      "VirusShare_2c9f54b86892c1cc41cafe750e4b210b.pe.asm not in asm file list.\n",
      "VirusShare_65e515a6bc38573fb2f05dc5171e7045.pe.asm not in asm file list.\n",
      "VirusShare_9ac69592c31e70d2b50c7b9d6c2497cf.pe.asm not in asm file list.\n",
      "VirusShare_fb8a402624813f36e3d24c483debcec3.pe.asm not in asm file list.\n",
      "VirusShare_f906baef57e171dcbe0e589f9f7a60ba.pe.asm not in asm file list.\n",
      "VirusShare_ae1adeee5da9ee9706f7a5dcb5ea7ff6.pe.asm not in asm file list.\n",
      "VirusShare_b9767368112ccf765598f5f5302e8bd9.pe.asm not in asm file list.\n",
      "VirusShare_2f31b23d02b52736860069bc166d5558.pe.asm not in asm file list.\n",
      "VirusShare_38fd79a16761ab3f15f934fcccd6d2a6.pe.asm not in asm file list.\n",
      "VirusShare_a81f4dcdd4121f62ab568c79f312ce3b.pe.asm not in asm file list.\n",
      "VirusShare_46e599795a7651f0c9a523d9e70bd640.pe.asm not in asm file list.\n",
      "VirusShare_b62e209b6d3503c5ca020eb1b1dac098.pe.asm not in asm file list.\n",
      "VirusShare_503ce666af676dba94de12b5af76ba7f.pe.asm not in asm file list.\n",
      "VirusShare_05d7d39b9f4564bb5a63a780f2dd5485.pe.asm not in asm file list.\n",
      "VirusShare_0e90fd02799c571b80f79b3bb1f779b4.pe.asm not in asm file list.\n",
      "VirusShare_155c7920dc89d75efff0d5654ffea657.pe.asm not in asm file list.\n",
      "VirusShare_cf0d753f76fca93c31e3bee98376546b.pe.asm not in asm file list.\n",
      "VirusShare_f2d1ee19f9cfda40e0a8f0bf271c8d91.pe.asm not in asm file list.\n",
      "VirusShare_a50a9f8314d138c8f1439a4bf53303fa.pe.asm not in asm file list.\n",
      "VirusShare_5eda6253d780410161a31dff1a61a8a6.pe.asm not in asm file list.\n",
      "VirusShare_2d940fc5b57a7342c4dcdbe08295abd4.pe.asm not in asm file list.\n",
      "VirusShare_7f8ab4a8660d948323a1cb4eb5c1a282.pe.asm not in asm file list.\n",
      "VirusShare_1e3b8ab8c0c55ed155dcd856a89c0ac4.pe.asm not in asm file list.\n",
      "VirusShare_de96d394a3580cfa52f10f212c0ee2c7.pe.asm not in asm file list.\n",
      "VirusShare_4f17b23d75115b6255def9756c52049b.pe.asm not in asm file list.\n",
      "VirusShare_fca49d96bf484abdf01ee4488964240e.pe.asm not in asm file list.\n",
      "VirusShare_8d3644b15d77a927919f1d856fcb2848.pe.asm not in asm file list.\n",
      "VirusShare_1bea4d02d5b43b3e10c22e8ca6e30d08.pe.asm not in asm file list.\n",
      "VirusShare_0c46f6273c746cfd7fba9352f68e6005.pe.asm not in asm file list.\n",
      "VirusShare_5cc065cfca3e9bb92313f36745a7788f.pe.asm not in asm file list.\n",
      "VirusShare_5970c56e7c37c234b072cf98911c853c.pe.asm not in asm file list.\n",
      "VirusShare_d56b67d7ed7c73840c618cd8c0172e91.pe.asm not in asm file list.\n",
      "VirusShare_2034431d8b0adc6a81987c177dde0495.pe.asm not in asm file list.\n",
      "VirusShare_040d88d7d684dd6707a6e2f514a87e3c.pe.asm not in asm file list.\n",
      "VirusShare_e5c074dd4ed54da04d4c324e066212df.pe.asm not in asm file list.\n",
      "VirusShare_4b57c804ebf754d03841020d2a918151.pe.asm not in asm file list.\n",
      "VirusShare_08e45c4bb0c81c1fea3d79c996302c09.pe.asm not in asm file list.\n",
      "VirusShare_8abe81a72c3a03a9964ae66d2bfa4606.pe.asm not in asm file list.\n",
      "VirusShare_6d7593749c6025b7d0bb1bde52a610ad.pe.asm not in asm file list.\n",
      "VirusShare_896c4e78ec1b3cc5d87111936baf7195.pe.asm not in asm file list.\n",
      "VirusShare_30234f9980748e075c3d323ff39d0a38.pe.asm not in asm file list.\n",
      "VirusShare_cfc9c102f23b9b77908b7494cc29b699.pe.asm not in asm file list.\n",
      "VirusShare_4ed46e313b37890d09b3637341fa7aae.pe.asm not in asm file list.\n",
      "VirusShare_376a1ab6e02fb0715eed0a892f498cc7.pe.asm not in asm file list.\n",
      "VirusShare_ad80c200efc71dad329a60f1803eb641.pe.asm not in asm file list.\n",
      "VirusShare_b77efe807711b96ecc41f33e42c00f44.pe.asm not in asm file list.\n",
      "VirusShare_4f152ec68ca279ff6cf46148aa96e53d.pe.asm not in asm file list.\n",
      "VirusShare_f240ae1d6cff83a1fd9d712e3150d926.pe.asm not in asm file list.\n",
      "VirusShare_f3ce48d3ad259cef63ca2f3bdfad6894.pe.asm not in asm file list.\n",
      "VirusShare_c4b6647d997cb30f2c2b98d65ac1c92f.pe.asm not in asm file list.\n",
      "VirusShare_fc5dfe06649c0f00491ca1f039e213e2.pe.asm not in asm file list.\n",
      "VirusShare_e9c7039005a20c684530f175c6b8cfe5.pe.asm not in asm file list.\n",
      "VirusShare_f143bfc527769f1dcf5b96bf8396cac6.pe.asm not in asm file list.\n",
      "VirusShare_090530172f97af115b25e5f7dc1a9258.pe.asm not in asm file list.\n",
      "VirusShare_4acb5a9ea2200d263ffab868756bbdb7.pe.asm not in asm file list.\n",
      "VirusShare_f0cf875de0eb1f40ba7c5c5aedbe27c8.pe.asm not in asm file list.\n",
      "VirusShare_f43aed027202f2c978371d088562fc56.pe.asm not in asm file list.\n",
      "VirusShare_105065a4286f7ac3591ea907f22f72ec.pe.asm not in asm file list.\n",
      "VirusShare_210021c265b12c15639b613b98a7aa1e.pe.asm not in asm file list.\n",
      "VirusShare_f33086badc0d9a5dfa7ebfe204d385f8.pe.asm not in asm file list.\n",
      "VirusShare_d32c62e18e7b0a96a272e00ca689ddc3.pe.asm not in asm file list.\n",
      "VirusShare_6ccc80825d64df53f5f6f1aa1bf4f4c8.pe.asm not in asm file list.\n",
      "VirusShare_496cb47de9ef7a4e762134a8fc1eb977.pe.asm not in asm file list.\n",
      "VirusShare_e6687365dd652ab86ab30eeb2aa4f296.pe.asm not in asm file list.\n",
      "VirusShare_3b59d46d37c1ccbcef4dbe799f769374.pe.asm not in asm file list.\n",
      "VirusShare_1160ead4664e48f1c2b36da946cf5d2f.pe.asm not in asm file list.\n",
      "VirusShare_c454f347daa681a19406d5c756b7c063.pe.asm not in asm file list.\n",
      "VirusShare_0a55c445e73dd41ed7eea32d6e1cfb88.pe.asm not in asm file list.\n",
      "VirusShare_f54e8c1752f4bdfa7b9d861ee5a1d939.pe.asm not in asm file list.\n",
      "VirusShare_401513b1e26dfd6e2668ad098c7b3109.pe.asm not in asm file list.\n",
      "VirusShare_f3bedda0d04722f4c9d4be2082a04afd.pe.asm not in asm file list.\n",
      "VirusShare_a2ba978c16d470e3c3be4f2a05da7227.pe.asm not in asm file list.\n",
      "VirusShare_97afb4be38cc9150028014e528e13f1b.pe.asm not in asm file list.\n",
      "VirusShare_fcb45d2169acd8965ed0e4196044fb81.pe.asm not in asm file list.\n",
      "VirusShare_aa1e4b9f826fa90c5ecc472cb2ce53ad.pe.asm not in asm file list.\n",
      "217 missing assembly files.\n",
      "Wrote 217 missing asm file names.\n",
      "VirusShare_6e5d5fd5906ca07dfd73259c5772be47.pe.asm bad output, filesize = 353.\n",
      "1 bad asm files.\n",
      "VirusShare_7dc02b8661b9cd6311943701c90aef4e.pe.txt bad output, filesize = 0.\n",
      "VirusShare_adbcb556aabf27758191f3be3f466c36.pe.txt bad output, filesize = 0.\n",
      "VirusShare_787d3645c5b5393984e7557daa389249.pe.txt bad output, filesize = 0.\n",
      "VirusShare_36cb828738111e0580a28607c713fcc7.pe.txt bad output, filesize = 0.\n",
      "VirusShare_592d7ac775519110d58e9ce1975c1b5b.pe.txt bad output, filesize = 0.\n",
      "VirusShare_4a0c79f6ad27b0a674b08005d102e16d.pe.txt bad output, filesize = 0.\n",
      "VirusShare_7e681c6b0488c8533389660c86a70982.pe.txt bad output, filesize = 0.\n",
      "VirusShare_d5eff38b212286c46db007aa7159ffd8.pe.txt bad output, filesize = 0.\n",
      "VirusShare_c80d9b2dbf9b7953a3b6e9b51a39a0c2.pe.txt bad output, filesize = 0.\n",
      "9 bad header files.\n",
      "Wrote 9 bad hdr file names.\n",
      "Wrote 1 bad asm file names.\n"
     ]
    }
   ],
   "source": [
    "validate_disassembly('/opt/vs/train1asm/', '/opt/vs/train1hdr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_elf_train1asm(ext_dir):\n",
    "    # Rename all the PE headers files so it is easier to process them.\n",
    "    \n",
    "    file_list = os.listdir(ext_dir)\n",
    "    elf_counter = 0\n",
    "    \n",
    "    print(\"Got total files: {:d}\".format(len(file_list)))\n",
    "    \n",
    "    for fname in file_list:\n",
    "        if 'elf' in fname:\n",
    "            elf_counter += 1\n",
    "            file_path = ext_dir + fname\n",
    "            #trunc_name = fname[0:fname.find('.elf')]\n",
    "            new_path = '/opt/vs/' + fname\n",
    "            result = sub.check_call(['mv', file_path, new_path])\n",
    "\n",
    "            #if (elf_counter % 1000) == 0:\n",
    "            print('ELF ASM file {:s}.'.format(file_path))\n",
    "\n",
    "    print('Completed move of {:d} ELF ASM files.'.format(elf_counter))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got total files: 54913\n",
      "ELF ASM file /opt/vs/train1asm/VirusShare_abbde81d7f4733c16046cbd8ee7409d3.elf.asm.\n",
      "ELF ASM file /opt/vs/train1asm/VirusShare_f04f278048fc082dd5d0f34efa3c05f8.elf.pe.asm.\n",
      "Completed move of 2 ELF ASM files.\n"
     ]
    }
   ],
   "source": [
    "find_elf_train1asm('/opt/vs/train1asm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_token_counts(token_counter_map, out_file):\n",
    "    # Output the malware sample classification counts.\n",
    "    fop = open(out_file, 'w')\n",
    "    csv_wouter = writer(fop)\n",
    "    cols = ['token_name','count'] # write out the column names.\n",
    "    csv_wouter.writerow(cols)\n",
    "    outlines = []\n",
    "    sorted_keys = token_counter_map.keys()\n",
    "    sorted_keys.sort()\n",
    "    counter = 0\n",
    "    for key in sorted_keys:\n",
    "        outlines.append([key, token_counter_map[key]])\n",
    "        counter += 1\n",
    "        if (counter % 100) == 0: # write out some lines\n",
    "            csv_wouter.writerows(outlines)\n",
    "            outlines = []\n",
    "            print(\"Processed token {:s} -> {:d}.\".format(key, token_counter_map[key]))\n",
    "\n",
    "    # Finish off.\n",
    "    if (len(outlines) > 0):\n",
    "        csv_wouter.writerows(outlines)\n",
    "        outlines = []\n",
    "\n",
    "    print(\"Completed writing {:d} tokens.\".format(len(sorted_keys)))    \n",
    "    fop.close()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_token_count_map(token_df):\n",
    "    # Read in the token count file and create a dict.\n",
    "    token_dict = {}\n",
    "    type_y = np.array(token_df['token_name'])\n",
    "    \n",
    "    for idx in range(token_df.shape[0]): # First fill the dict with the token counts\n",
    "        token_dict[token_df.iloc[idx,0]] = token_df.iloc[idx,1]\n",
    "        \n",
    "\n",
    "    return token_dict\n",
    "\n",
    "\n",
    "def combine_token_files():\n",
    "    # TODO: everything\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def generate_pe_tokens(file_list, out_token_file, out_count_file):\n",
    "\n",
    "    psections = re.compile('\\s+\\d{1,2}\\s+(\\.\\w+|\\w+)\\s+\\d+')            # Pattern for section names.\n",
    "    pdlls = re.compile('\\s+DLL Name: (\\w+)')                  # Pattern for import DLL names.\n",
    "    pfunctions = re.compile('\\s+\\w+\\s+\\d{1,4}\\s+(.+)')        # Pattern for import function names.\n",
    "    preloc = re.compile('\\s+reloc')                           # Pattern for relocation entries.\n",
    "    pexports = re.compile('\\s+\\[\\s*\\d+\\]\\s+(\\w+)')            # Pattern for exported function names.\n",
    "    \n",
    "    token_counter_map = {}\n",
    "    counter = 0\n",
    "    pid = os.getpid()\n",
    "    \n",
    "    for idx, fname in enumerate(file_list):\n",
    "\n",
    "        fip = open(fname, 'r')\n",
    "        in_lines = fip.readlines()\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        for line in in_lines:\n",
    "\n",
    "            line = line.rstrip() # get rid of newlines they are annoying.\n",
    "            token_val = \"\"\n",
    "            \n",
    "            m = preloc.match(line)\n",
    "            if m != None:\n",
    "                #token_val = m.group(2)\n",
    "                continue\n",
    "\n",
    "            m = psections.match(line)\n",
    "            if m != None:\n",
    "                token_val = m.group(1)\n",
    "                print(\"Section: {:s}\".format(token_val))\n",
    "            else:\n",
    "                m = pdlls.match(line)\n",
    "                if m != None:\n",
    "                    token_val = m.group(1)\n",
    "                else:\n",
    "                    m = pfunctions.match(line)\n",
    "                    if m != None:\n",
    "                        token_val = m.group(1)\n",
    "                    else:                 \n",
    "                        m = pexports.match(line)\n",
    "                        if m != None:\n",
    "                            token_val = m.group(1)\n",
    "                            print(\"Export: {:s}\".format(token_val))\n",
    "                        else:   \n",
    "                            continue\n",
    "                        \n",
    "            # Count the token type.\n",
    "            if token_val in token_counter_map.keys():\n",
    "                token_counter_map[token_val] += 1\n",
    "            else:\n",
    "                token_counter_map[token_val] = 1\n",
    "\n",
    "\n",
    "        if (counter % 100) == 0:\n",
    "            print(\"{:d} Processed {:d} header files.\".format(pid, counter))\n",
    "\n",
    "        fip.close()\n",
    "        \n",
    "        \n",
    "    save_token_counts(token_counter_map, out_count_file)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ext_drive = '/opt/vs/hdr/'\n",
    "file_list = os.listdir(ext_drive)\n",
    "file_paths = []\n",
    "\n",
    "for fname in file_list:\n",
    "    file_paths.append(ext_drive + fname)\n",
    "    \n",
    "generate_pe_tokens(file_paths,'data/pe-header-tokens-apt.txt','data/pe-coff-header-token-counts-apt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing PE header token generation.\n",
    "\n",
    "def save_token_counts(token_counter_map, out_file_name):\n",
    "    # Output the PE Header token counts.\n",
    "    pid = os.getpid()\n",
    "    out_file = \"data/\" + str(pid) + \"-\" + out_file_name\n",
    "    fop = open(out_file, 'w')\n",
    "    csv_wouter = writer(fop)\n",
    "\n",
    "    outlines = []\n",
    "    sorted_keys = token_counter_map.keys()\n",
    "    sorted_keys.sort()\n",
    "    counter = 0\n",
    "    \n",
    "    for key in sorted_keys:\n",
    "        outlines.append([key, token_counter_map[key]])\n",
    "        counter += 1\n",
    "        if (counter % 100) == 0: # write out some lines\n",
    "            csv_wouter.writerows(outlines)\n",
    "            outlines = []\n",
    "            print(\"Processed token {:s} -> {:d}.\".format(key, token_counter_map[key]))\n",
    "\n",
    "    # Finish off.\n",
    "    if (len(outlines) > 0):\n",
    "        csv_wouter.writerows(outlines)\n",
    "        outlines = []\n",
    "\n",
    "    print(\"Completed writing {:d} tokens.\".format(len(sorted_keys)))    \n",
    "    fop.close()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def get_token_count_map(token_df):\n",
    "    # Read in the token count file and create a dict.\n",
    "    token_dict = {}\n",
    "    type_y = np.array(token_df['token_name'])\n",
    "    \n",
    "    for idx in range(token_df.shape[0]): # First fill the dict with the token counts\n",
    "        token_dict[token_df.iloc[idx,0]] = token_df.iloc[idx,1]\n",
    "        \n",
    "\n",
    "    return token_dict\n",
    "\n",
    "    \n",
    "def generate_pe_tokens(mp_params):\n",
    "    # Parse a bunch of PE/COFF headers dumped by objdump and extract\n",
    "    # section names, import DLLs, import functions and exported functions.\n",
    "    file_list = mp_params.file_list\n",
    "    out_count_file = mp_params.count_file\n",
    "    \n",
    "    psections = re.compile('\\s+\\d{1,2}\\s+(\\.\\w+|\\w+)\\s+\\d+')  # Pattern for section names.\n",
    "    pdlls = re.compile('\\s+DLL Name: (\\w+)')                  # Pattern for import DLL names.\n",
    "    pfunctions = re.compile('\\s+\\w+\\s+\\d{1,4}\\s+(.+)')        # Pattern for import function names.\n",
    "    preloc = re.compile('\\s+reloc')                           # Pattern for relocation entries.\n",
    "    pexports = re.compile('\\s+\\[\\s*\\d+\\]\\s+(\\w+)')            # Pattern for exported function names.\n",
    "    \n",
    "    token_counter_map = {}\n",
    "    counter = 0\n",
    "    pid = os.getpid()\n",
    "    \n",
    "    for idx, fname in enumerate(file_list):\n",
    "\n",
    "        fip = open(fname, 'r')\n",
    "        in_lines = fip.readlines()\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        for line in in_lines:\n",
    "\n",
    "            line = line.rstrip() # get rid of newlines they are annoying.\n",
    "            token_val = \"\"\n",
    "            \n",
    "            m = preloc.match(line)\n",
    "            if m != None:\n",
    "                #token_val = m.group(2)\n",
    "                continue\n",
    "\n",
    "            m = psections.match(line)\n",
    "            if m != None:\n",
    "                token_val = m.group(1)\n",
    "                #print(\"Section: {:s}\".format(token_val))\n",
    "            else:\n",
    "                m = pdlls.match(line)\n",
    "                if m != None:\n",
    "                    token_val = m.group(1)\n",
    "                else:\n",
    "                    m = pfunctions.match(line)\n",
    "                    if m != None:\n",
    "                        token_val = m.group(1)\n",
    "                    else:                 \n",
    "                        m = pexports.match(line)\n",
    "                        if m != None:\n",
    "                            token_val = m.group(1)\n",
    "                            #print(\"Export: {:s}\".format(token_val))\n",
    "                        else:   \n",
    "                            continue\n",
    "                        \n",
    "            # Count the token type.\n",
    "            if token_val in token_counter_map.keys():\n",
    "                token_counter_map[token_val] += 1\n",
    "            else:\n",
    "                token_counter_map[token_val] = 1\n",
    "\n",
    "\n",
    "        if (counter % 100) == 0:\n",
    "            print(\"{:d} Processed {:d} header files.\".format(pid, counter))\n",
    "\n",
    "        fip.close()\n",
    "        \n",
    "        \n",
    "    save_token_counts(token_counter_map, out_count_file)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def save_combine(token_counter_map, out_file_name):\n",
    "    # Save the combined token counts.\n",
    "    \n",
    "    out_file = \"data/\" + out_file_name\n",
    "    fop = open(out_file, 'w')\n",
    "    csv_wouter = writer(fop)\n",
    "    cols = ['token_name','count'] \n",
    "    csv_wouter.writerow(cols)\n",
    "    \n",
    "    outlines = []\n",
    "    sorted_keys = token_counter_map.keys()\n",
    "    sorted_keys.sort()\n",
    "    counter = 0\n",
    "    \n",
    "    for key in sorted_keys:\n",
    "        outlines.append([key, token_counter_map[key]])\n",
    "        counter += 1\n",
    "        if (counter % 100) == 0: # write out some lines\n",
    "            csv_wouter.writerows(outlines)\n",
    "            outlines = []\n",
    "            print(\"Processed token {:s} -> {:d}.\".format(key, token_counter_map[key]))\n",
    "\n",
    "    # Finish off.\n",
    "    if (len(outlines) > 0):\n",
    "        csv_wouter.writerows(outlines)\n",
    "        outlines = []\n",
    "\n",
    "    fop.close()\n",
    "    \n",
    "    print(\"Completed writing {:d} tokens.\".format(len(sorted_keys)))  \n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def combine_token_files(token_file, count_file):\n",
    "    # Function to combine the newly generated token files into one file:\n",
    "    # 1. list data directory\n",
    "    # 2. For each file in file list that matches (\\d\\d\\d\\d-pe-header-tokens.csv)\n",
    "    # 3. Trim the filenames if necessary (should remove VirusShare_  prefix).\n",
    "    # 4. Concatenate the unsorted token feature files.\n",
    "    # 5. Sort and write to data/sorted-token-features.csv\n",
    "\n",
    "    \n",
    "    p1 = re.compile('\\d{3,5}-' + count_file) # This is the PID prefix for each file.\n",
    "    file_list = os.listdir('data/')\n",
    "    counter = 0\n",
    "    token_map = {}\n",
    "    \n",
    "    for file_name in file_list:\n",
    "        if p1.match(file_name):\n",
    "            fip = open('data/' + file_name, 'r')\n",
    "            in_lines = fip.readlines()\n",
    "            for line in in_lines:\n",
    "                tokens = line.split(',')\n",
    "                if tokens[0] not in token_map.keys():\n",
    "                    token_map[tokens[0]] = int(tokens[1])\n",
    "                else:\n",
    "                    token_map[tokens[0]] += int(tokens[1])\n",
    "                    \n",
    "            counter += len(in_lines)\n",
    "            fip.close()\n",
    "            \n",
    " \n",
    "\n",
    "    save_combine(token_map, token_file)\n",
    "    \n",
    "    print('Completed combine of {:d} PE/COFF header tokens.'.format(counter)) \n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "class Multi_Params(object):\n",
    "    def __init__(self, tokenfile=\"\", countfile=\"\", filelist=[]):\n",
    "        self.token_file = tokenfile\n",
    "        self.count_file = countfile\n",
    "        self.file_list = filelist\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_file = 'pe-header-tokens-apt.txt'\n",
    "count_file = 'pe-header-token-counts-apt.csv'\n",
    "ext_drive = '/opt/vs/apthdr/'\n",
    "file_list = os.listdir(ext_drive)\n",
    "tfiles = []\n",
    "\n",
    "for fname in file_list:\n",
    "    tfiles.append(ext_drive + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mp1 = Multi_Params(token_file, count_file, tfiles)\n",
    "\n",
    "generate_pe_tokens(mp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed token AdjustTokenPrivileges -> 63.\n",
      "Processed token CryptGetUserKey -> 3.\n",
      "Processed token GetAdaptersInfo -> 2.\n",
      "Processed token GetSystemTimeAsFileTime -> 29.\n",
      "Processed token IsValidLocale -> 7.\n",
      "Processed token OutputDebugStringA -> 32.\n",
      "Processed token SHCreateDirectoryExA -> 7.\n",
      "Processed token UnhandledExceptionFilter -> 64.\n",
      "Processed token _configthreadlocale -> 2.\n",
      "Processed token free -> 120.\n",
      "Processed token wsprintfA -> 20.\n",
      "Completed writing 1103 tokens.\n",
      "Completed combine of 1103 PE/COFF header tokens.\n"
     ]
    }
   ],
   "source": [
    "combine_token_files(token_file, count_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing PE header feature extraction.\n",
    "\n",
    "field_list = [ \"Characteristics\",\"Time/Date\",\"Magic\",\"MajorLinkerVersion\",\"MinorLinkerVersion\",\n",
    "\"SizeOfCode\",\"SizeOfInitializedData\",\"SizeOfUninitializedData\",\"AddressOfEntryPoint\",\n",
    "\"BaseOfCode\",\"BaseOfData\",\"ImageBase\",\"SectionAlignment\",\"FileAlignment\",\n",
    "\"MajorOSystemVersion\",\"MinorOSystemVersion\",\"MajorImageVersion\",\"MinorImageVersion\",\n",
    "\"MajorSubsystemVersion\",\"MinorSubsystemVersion\",\"Win32Version\",\n",
    "\"SizeOfImage\",\"SizeOfHeaders\",\"CheckSum\",\"Subsystem\",\"DllCharacteristics\",\"SizeOfStackReserve\",\n",
    "\"SizeOfStackCommit\",\"SizeOfHeapReserve\",\"SizeOfHeapCommit\",\"LoaderFlags\",\"NumberOfRvaAndSizes\" ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_field_values(header_lines):\n",
    "\n",
    "    field_vals = [0] * len(field_list)\n",
    "    \n",
    "    for idx1 in range(0,44): # The PE header fields are the first 44 lines of the file.\n",
    "        \n",
    "        line = header_lines[idx1].rstrip()\n",
    "        tokens = line.split()\n",
    "        \n",
    "        for idx2, field_name in enumerate(field_list):\n",
    "            \n",
    "            if field_name in tokens:\n",
    "                if field_name.startswith(\"Time\"):\n",
    "                    time_match = ptime.match(field_name)\n",
    "                    if time_match != None:   \n",
    "                        time_str = time_match.group(1) \n",
    "                        time_s = tm.strptime(time_str, \"%a %b %d %H:%M:%S %Y\") # Convert time string to epoch int.\n",
    "                        time_epoch = tm.mktime(time_s)\n",
    "                    else:\n",
    "                        time_epoch = 0\n",
    "                        \n",
    "                    field_vals[idx2] = time_epoch\n",
    "\n",
    "                elif len(tokens) > 1:\n",
    "                    field_vals[idx2] = int(tokens[1], 16) # Convert the hex value of the field to int.\n",
    "                \n",
    "    return field_vals\n",
    "                \n",
    "                \n",
    "def count_header_keywords(asm_code, keywords, klen):\n",
    "    \n",
    "    keywords_values = [0] * klen\n",
    "    \n",
    "    for row in asm_code:\n",
    "        for i in range(klen):\n",
    "            if keywords[i] in row:\n",
    "                keywords_values[i] += 1\n",
    "                break\n",
    "                \n",
    "    return keywords_values\n",
    "\n",
    "\n",
    "def extract_header_features(multi_parameters):\n",
    "    # 1. Get the feature file and token/keyword file names\n",
    "    # 2. Create an array of token/keyword values.\n",
    "    # 3. Iterate throught the PE header file list and counter the occurrence of the keywords in each file.\n",
    "\n",
    "    pid = os.getpid()\n",
    "    feature_file = 'data/' + str(pid) + \"-\" + multi_parameters.out_file  \n",
    "    token_file = 'data/' + multi_parameters.token_file\n",
    "    \n",
    "    print('Process id: {:d} - Feature file: {:s} - Keyword file: {:s}'.format(pid, feature_file, token_file))\n",
    "\n",
    "    hdr_pd = pd.read_csv(token_file)\n",
    "    tokens = list(hdr_pd['token_name'])\n",
    "    tlen = len(tokens)\n",
    "\n",
    "    for idx, token in enumerate(tokens): # Clamp the token name length.\n",
    "        if len(token) > 32:\n",
    "            tokens[idx] = token[:32]\n",
    "            \n",
    "    asm_files = [i for i in tfiles if '.pe.txt' in i]\n",
    "    ftot = len(asm_files)\n",
    "    \n",
    "    feature_counts = []\n",
    "    with open(feature_file, 'w') as f:\n",
    "\n",
    "        fw = writer(f)\n",
    "        \n",
    "        for idx, fname in enumerate(asm_files):\n",
    "            \n",
    "            fasm = open(ext_drive + fname, 'r')\n",
    "            content = fasm.readlines()\n",
    "            fasm.close()\n",
    "            \n",
    "            fname = fname[fname.find(\"_\")+1:] # Remove VirusShare_ from the start of the file name.\n",
    "            \n",
    "            field_vals = get_field_values(content)\n",
    "            keyword_vals = count_header_keywords(content, tokens, tlen)\n",
    "            \n",
    "            feature_counts.append([fname[0:fname.find('.pe.txt')]] + field_vals + keyword_vals)   \n",
    "            \n",
    "            # Writing rows after every 10 files processed\n",
    "            if (idx+1) % 10 == 0:\n",
    "                print(\"{:d} - {:d} of {:d} files processed.\".format(pid, idx + 1, ftot))\n",
    "                fw.writerows(feature_counts)\n",
    "                feature_counts = []\n",
    "                \n",
    "        # Writing remaining features\n",
    "        if len(feature_counts) > 0:\n",
    "            fw.writerows(feature_counts)\n",
    "            feature_counts = []\n",
    "\n",
    "    print(\"{:d} Completed processing {:d} PE header files.\".format(pid, ftot))\n",
    "                      \n",
    "    return\n",
    "\n",
    "\n",
    "def combine_feature_files(feature_file_name, token_file):\n",
    "    # Function to combine the newly generated PE header feature files into one file:\n",
    "    # 1. list data directory\n",
    "    # 2. For each file in file list that matches (\\d\\d\\d\\d-pe-header-features.csv)\n",
    "    # 3. Trim the filenames if necessary (should remove VirusShare_  prefix).\n",
    "    # 4. Concatenate the unsorted pe header feature files.\n",
    "    # 5. Sort and write to data/sorted-pe-header-features.csv\n",
    "    \n",
    "    hdr_pd = pd.read_csv('data/' + token_file)\n",
    "    tokens = list(hdr_pd['token_name'])\n",
    "    for idx, token in enumerate(tokens): # Clamp the token name length.\n",
    "        if len(token) > 32:\n",
    "            tokens[idx] = token[:32]    \n",
    "    \n",
    "    fop = open('data/' + feature_file_name,'w')\n",
    "    colnames = \"file_name,\" + \",\".join(field_list) + \",\" + \",\".join(tokens)\n",
    "    print(\"Column names: {:s}\".format(colnames))\n",
    "    fop.write(colnames)                    \n",
    "\n",
    "    p1 = re.compile('\\d{3,5}-' + feature_file_name) # This is the PID prefix for each file.\n",
    "    file_list = os.listdir('data/')\n",
    "    counter = 0\n",
    "    \n",
    "    for file_name in file_list:\n",
    "        if p1.match(file_name):\n",
    "            fip = open('data/' + file_name, 'r')\n",
    "            in_lines = fip.readlines()\n",
    "            fop.writelines(in_lines)\n",
    "            counter += len(in_lines)\n",
    "            fip.close()\n",
    "            \n",
    "    \n",
    "    fop.close()\n",
    "    \n",
    "    features = pd.read_csv('data/' + feature_file_name)\n",
    "    # DataFrame.sort() is deprecated, but this is an old version of pandas, does not have sort_values().\n",
    "    sorted_features = features.sort('file_name')\n",
    "    sorted_features.to_csv('data/sorted-' + feature_file_name, index=False)\n",
    "    \n",
    "    print('Completed combine of {:d} PE header file features.'.format(counter))  \n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "class Multi_Params(object):\n",
    "    def __init__(self, outfile=\"\", tokenfile=\"\", fieldnames=[], filelist=[]):\n",
    "        self.out_file = outfile\n",
    "        self.token_file = tokenfile\n",
    "        self.field_names = fieldnames\n",
    "        self.file_list = filelist\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ptime = re.compile(\"Time/Date\\w+(.+)\") # Time/Date pattern for PE Header field.\n",
    "\n",
    "header_field_names = 'pe-coff-header-field-names.txt'\n",
    "out_file = 'pe-header-features-apt.csv'\n",
    "token_file = 'pe-header-tokens-apt.csv'\n",
    "ext_drive = '/opt/vs/apthdr/'\n",
    "tfiles = os.listdir(ext_drive)\n",
    "\n",
    "mp1 = Multi_Params(out_file, token_file, header_field_names, tfiles)\n",
    "\n",
    "extract_header_features(mp1)\n",
    "\n",
    "combine_feature_files(out_file, token_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combine_feature_files(out_file, token_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test PE ASM feature extraction.\n",
    "\n",
    "x86_registers = ['edx','esi','es','fs','ds','ss','gs','cs','ah','al',\n",
    "                 'ax','bh','bl','bx','ch','cl','cx','dh','dl','dx',\n",
    "                 'eax','ebp','ebx','ecx','edi','esp']\n",
    "\n",
    "x86_opcodes = ['add','al','bt','call','cdq','cld','cli','cmc','cmp','const','cwd','daa','db'\n",
    "                ,'dd','dec','dw','endp','ends','faddp','fchs','fdiv','fdivp','fdivr','fild'\n",
    "                ,'fistp','fld','fstcw','fstcwimul','fstp','fword','fxch','imul','in','inc'\n",
    "                ,'ins','int','jb','je','jg','jge','jl','jmp','jnb','jno','jnz','jo','jz'\n",
    "                ,'lea','loope','mov','movzx','mul','near','neg','not','or','out','outs'\n",
    "                ,'pop','popf','proc','push','pushf','rcl','rcr','rdtsc','rep','ret','retn'\n",
    "                ,'rol','ror','sal','sar','sbb','scas','setb','setle','setnle','setnz'\n",
    "                ,'setz','shl','shld','shr','sidt','stc','std','sti','stos','sub','test'\n",
    "                ,'wait','xchg','xor']\n",
    "\n",
    "\n",
    "def count_asm_registers(asm_code):\n",
    "    registers_values = [0]*len(x86_registers) # Need to optimise this init stuff to global vars.\n",
    "    \n",
    "    for row in asm_code:\n",
    "        parts = row.replace(',',' ').replace('+',' ').replace('*',' ').replace('[',' ').replace(']',' ') \\\n",
    "                    .replace('-',' ').split()\n",
    "\n",
    "        for idx, register in enumerate(x86_registers):\n",
    "            registers_values[idx] += parts.count(register)\n",
    "\n",
    "    return registers_values\n",
    "\n",
    "\n",
    "def count_asm_opcodes(asm_code):\n",
    "    opcodes_values = [0]*len(x86_opcodes)\n",
    "    \n",
    "    for row in asm_code:\n",
    "        parts = row.split()\n",
    "\n",
    "        for idx, opcode in enumerate(x86_opcodes):\n",
    "            if opcode in parts:\n",
    "                opcodes_values[idx] += 1\n",
    "                break\n",
    "\n",
    "    return opcodes_values\n",
    "\n",
    "def extract_asm_features(multi_param):\n",
    "    \n",
    "    pid = os.getpid()\n",
    "    feature_file = 'data/' + str(pid) + \"-\" + multi_param.temp_file\n",
    "    print('Process id: {:d} feature file: {:s}'.format(pid,feature_file))\n",
    "\n",
    "    # Do this in call graph feature extraction.\n",
    "    #fapi = open(\"data/APIs.txt\")\n",
    "    #defined_apis = fapi.readlines()\n",
    "    #defined_apis = defined_apis[0].split(',')\n",
    "\n",
    "    asm_files = [i for i in tfiles if '.asm' in i]\n",
    "    ftot = len(asm_files)\n",
    "    \n",
    "    feature_counts = []\n",
    "    with open(feature_file, 'w') as f:\n",
    "        \n",
    "        fw = writer(f)\n",
    "        \n",
    "        for idx, fname in enumerate(asm_files):\n",
    "            \n",
    "            fasm = open(ext_drive + fname, 'r')\n",
    "            content = fasm.readlines()\n",
    "            fasm.close()\n",
    "            \n",
    "            fname = fname[fname.find(\"_\")+1:] # Remove VirusShare_ from the start of the file name.\n",
    "            \n",
    "            reg_vals = count_asm_registers(content)\n",
    "            opc_vals = count_asm_opcodes(content)\n",
    "            #api_vals = count_asm_APIs(content, defined_apis) put in Call Graph features.\n",
    "            #sec_vals = count_asm_sections(content) already in PE header features.\n",
    "            #mis_vals = count_asm_misc(content) mostly already in PE header and call graph features.\n",
    "            count_vals = reg_vals + opc_vals # + api_vals + mis_vals\n",
    "            \n",
    "            feature_counts.append([fname[:fname.find('.asm')]] + count_vals)   \n",
    "            \n",
    "            # Writing rows after every 10 files processed\n",
    "            if (idx+1) % 10 == 0:\n",
    "                print(\"{:d} {:d} of {:d} files processed.\".format(pid, idx + 1, ftot))\n",
    "                fw.writerows(feature_counts)\n",
    "                feature_counts = []\n",
    "                \n",
    "        # Writing remaining files\n",
    "        if len(feature_counts) > 0:\n",
    "            fw.writerows(feature_counts)\n",
    "            feature_counts = []\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def combine_asm_files(out_file, temp_file):\n",
    "    # Function to combine the newly generated asm feature files into one file:\n",
    "    # 1. list data directory\n",
    "    # 2. For each file in file list that matches (\\d\\d\\d\\d-asm-features.csv)\n",
    "    # 3. Trim the filenames if necessary (should remove VirusShare_  prefix).\n",
    "    # 4. Concatenate the unsorted asm feature files.\n",
    "    # 5. Sort and write to data/sorted-asm-features.csv\n",
    "    fop = open('data/' + out_file,'w')\n",
    "    colnames = \"file_name,\" + \",\".join(x86_registers) + \",\" + \",\".join(x86_opcodes) + \"\\n\"\n",
    "    fop.write(colnames)\n",
    "    \n",
    "    print(\"Column names: {:s}\".format(colnames))\n",
    "    \n",
    "    p1 = re.compile('\\d{3,5}-' + temp_file) # This is the PID prefix for each file.\n",
    "    file_list = os.listdir('data/')\n",
    "    counter = 0\n",
    "    \n",
    "    for file_name in file_list:\n",
    "        if p1.match(file_name):\n",
    "            fip = open('data/' + file_name, 'r')\n",
    "            in_lines = fip.readlines()\n",
    "            fop.writelines(in_lines)\n",
    "            counter += len(in_lines)\n",
    "            fip.close()\n",
    "            \n",
    "    print('Completed combine of {:d} ASM features.'.format(counter))  \n",
    "    \n",
    "    fop.close()\n",
    "    \n",
    "    asms = pd.read_csv('data/' + out_file)\n",
    "    # DataFrame.sort() is deprecated, but this is an old version of pandas, does not have sort_values().\n",
    "    sorted_asms = asms.sort('file_name')\n",
    "    sorted_asms.to_csv('data/sorted-' + out_file, index=False)\n",
    "    sorted_asms.head(20)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "class Multi_Params(object):\n",
    "    def __init__(self, featurefile=\"\", tempfile=\"\", filelist=[]):\n",
    "        self.feature_file = featurefile\n",
    "        self.temp_file = tempfile\n",
    "        self.file_list = filelist\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_file = 'pe-asm-features-apt.csv'\n",
    "temp_file = 'pe-asm-temp-apt.csv'\n",
    "ext_drive = '/opt/vs/asm/'\n",
    "tfiles = os.listdir(ext_drive)\n",
    "\n",
    "mp1 = Multi_Params(out_file, temp_file, tfiles)\n",
    "\n",
    "\n",
    "extract_asm_features(mp1)\n",
    "\n",
    "\n",
    "combine_asm_files(out_file, temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combine_asm_files(out_file, temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unpacked_file_list(packer_id_feature_file, file_id_feature_file, trid_id_feature_file):\n",
    "    # Load the malware packer id features and file id features from the sample set.\n",
    "    packer_id_features = pd.read_csv(packer_id_feature_file)\n",
    "    file_id_features = pd.read_csv(file_id_feature_file)\n",
    "    trid_id_features = pd.read_csv(trid_id_feature_file)\n",
    "    \n",
    "    # Get a list of unpacked PE files that are not .NET CIL format.\n",
    "    # IDA Pro cannot disassemble .NET files, have to use Ildisasm.exe in Visual Studio.\n",
    "    unpacked_files = packer_id_features[packer_id_features['is_packed'] == 0]\n",
    "    unpacked_pe_files = unpacked_files[unpacked_files['valid_pe'] == 1]\n",
    "    not_dot_net = []\n",
    "    counter = 0\n",
    "    dot_net_counter = 0\n",
    "    \n",
    "    # Get the trid and file rows that are for unpacked PE files.\n",
    "    trids = trid_id_features[trid_id_features['file_name'].isin(unpacked_pe_files['file_name'])]\n",
    "    fids = file_id_features[file_id_features['file_name'].isin(unpacked_pe_files['file_name'])]\n",
    "    \n",
    "    # Iterate over the unpacked PE file list and check if each is a .NET file.\n",
    "    # If not a .NET file then add to file list.\n",
    "    pe_names_list = unpacked_pe_files['file_name']\n",
    "    \n",
    "    for idx, file_name in enumerate(pe_names_list):\n",
    "        trid_name = trids.iloc[idx, 1]\n",
    "        fid_name = fids.iloc[idx, 1]\n",
    "        trid_name = trid_name.lower()\n",
    "        fid_name = fid_name.lower()\n",
    "        \n",
    "        if trid_name.find('.net') > -1 or fid_name.find('.net') > -1:\n",
    "            #print('Found: {:s} - {:s}'.format(trid_name, fid_name))\n",
    "            dot_net_counter += 1\n",
    "            continue\n",
    "            \n",
    "        #print('Found: {:s} - {:s}'.format(trid_name, fid_name))\n",
    "        not_dot_net.append(file_name)\n",
    "        counter += 1\n",
    "    \n",
    "    file_list = []\n",
    "    write_list = []\n",
    "    counter = 0\n",
    "    \n",
    "    # Iterate over the file list and prepend the full file name.\n",
    "    for file_name in not_dot_net:\n",
    "        full_name = \"VirusShare_\" + file_name\n",
    "        file_list.append(full_name)\n",
    "        write_list.append(full_name + \"\\n\")\n",
    "        counter += 1\n",
    "\n",
    "    if (len(file_list) > 0):   \n",
    "        fop = open('data/temp-unpacked-pe-non-dot-net.txt','w')\n",
    "        fop.writelines(write_list)\n",
    "        fop.close()\n",
    "    \n",
    "    print(\"Got {:d} unpacked PE filenames and {:d} .NET filenames.\".format(counter, dot_net_counter))\n",
    "\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 55128 unpacked PE filenames and 348 .NET filenames.\n",
      "Got 21315 completed ASM files.\n",
      "Processing 33814 files out of 55128 total unpacked PE files.\n"
     ]
    }
   ],
   "source": [
    "packer_id_file = 'data/sorted-packer-id-features-vs251.csv'\n",
    "file_id_file = 'data/sorted-file-id-features-vs251.csv'\n",
    "trid_id_file = 'data/sorted-trid-id-features-vs251.csv'\n",
    "ext_drive = '/opt/vs/train1/'\n",
    "\n",
    "unflist = get_unpacked_file_list(packer_id_file, file_id_file, trid_id_file)\n",
    "\n",
    "file_list = []\n",
    "completed_list = os.listdir('/opt/vs/train1asm/')\n",
    "print(\"Got {:d} completed ASM files.\".format(len(completed_list)))\n",
    "for idx, fname in enumerate(completed_list):\n",
    "    completed_list[idx] = fname[0:fname.find(\".asm\")]\n",
    "\n",
    "for idx, fname in enumerate(unflist):\n",
    "    if fname not in completed_list:\n",
    "        file_list.append(ext_drive + fname)\n",
    "\n",
    "print(\"Processing {:d} files out of {:d} total unpacked PE files.\".format(len(file_list), len(unflist)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55129"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "33814 + 21315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test ELF disassembly.\n",
    "\n",
    "def get_elf_file_list(ext_drive, packer_id_feature_file, file_id_feature_file, trid_id_feature_file):\n",
    "    # Load the malware packer id features and file id features from the sample set.\n",
    "    packer_id_features = pd.read_csv(packer_id_feature_file)\n",
    "    file_id_features = pd.read_csv(file_id_feature_file)\n",
    "    trid_id_features = pd.read_csv(trid_id_feature_file)\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    file_names_list = file_id_features['file_name']\n",
    "    file_list = []\n",
    "    write_list = []\n",
    "    fid_list = []\n",
    "    \n",
    "    for idx, file_name in enumerate(file_names_list):\n",
    "        trid_name = trid_id_features.iloc[idx, 1]\n",
    "        fid_name = file_id_features.iloc[idx, 1]\n",
    "        \n",
    "        if trid_name.find('ELF') > -1 or fid_name.find('ELF') > -1:\n",
    "            print('Found: {:s} - {:s}'.format(trid_name, fid_name))\n",
    "            counter += 1\n",
    "            full_name = ext_drive + \"VirusShare_\" + file_name\n",
    "            write_list =  full_name + \"\\n\"\n",
    "            file_list.append(full_name)\n",
    "            fid_list.append(fid_name)\n",
    "\n",
    "\n",
    "        \n",
    "    fop = open('data/elf-file-list.txt','w')\n",
    "    fop.writelines(write_list)\n",
    "    fop.close()\n",
    "    \n",
    "    print(\"Got {:d} ELF filenames.\".format(counter))\n",
    "\n",
    "    return file_list, fid_list\n",
    "\n",
    "\n",
    "\n",
    "def disassemble_elf_binaries(file_list, fid_list):\n",
    "    # Use the command \"objdump -d -M intel file_name\" to dump out all \n",
    "    # the code sections of the ELF binary and generate assembly code in Intel\n",
    "    # format as this is easier to read and better for machine learning \n",
    "    # feature extraction.\n",
    "    # Use the command \"objdump -g -x file_name -o file_name.txt to dump out\n",
    "    # all header sections.\n",
    "    \n",
    "    counter = 0\n",
    "    disassed = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    print(\"Disassembling {:d} binary ELF files.\".format(len(file_list)))\n",
    "    \n",
    "    for idx, file_name in enumerate(file_list):\n",
    "        file_path = file_name.rstrip() # remove the newlines or else !!!\n",
    "        asm_file_name = file_path + \".elf.asm\"\n",
    "        hdr_file_name = file_path + \".elf.txt\"\n",
    "        fid_name = fid_list[idx]\n",
    "        \n",
    "        if (os.path.isfile(file_path)):\n",
    "            fopasm = open(asm_file_name, \"w\")\n",
    "            # Dump the assembly code listing.\n",
    "            if \"Intel\" in fid_name:\n",
    "                sub.call([\"objdump\", \"-d\", \"-M intel\", file_path], stdout=fopasm)\n",
    "                #sub.call([\"ndisasm\", \"-d\", \"-M intel\", file_path], stdout=fopasm)\n",
    "            elif \"x86\" in fid_name:\n",
    "                sub.call([\"objdump\", \"-d\", \"-M intel\", file_path], stdout=fopasm)\n",
    "            elif \"ARM\" in fid_name:\n",
    "                sub.call([\"objdump\", \"-d\", \"-marm\", file_path], stdout=fopasm)\n",
    "            elif \"PowerPC\" in fid_name:\n",
    "                sub.call([\"objdump\", \"-d\", \"-mpowerpc\", file_path], stdout=fopasm)\n",
    "            elif \"Motorola\" in fid_name:\n",
    "                sub.call([\"objdump\", \"-d\", \"-mm68k\", file_path], stdout=fopasm)\n",
    "            elif \"SPARC\" in fid_name:\n",
    "                sub.call([\"objdump\", \"-d\", \"-msparc\", file_path], stdout=fopasm)\n",
    "            elif \"MIPS\" in fid_name:\n",
    "                sub.call([\"objdump\", \"-d\", \"-mmips\", file_path], stdout=fopasm)\n",
    "            elif \"Renesas\" in fid_name: # SuperH\n",
    "                sub.call([\"objdump\", \"-d\", \"-msh\", file_path], stdout=fopasm)\n",
    "                \n",
    "            # Dump the ELF section headers.\n",
    "            fophdr = open(hdr_file_name, \"w\")\n",
    "            sub.call([\"readelf\", \"-e\", file_path], stdout=fophdr)\n",
    "            fophdr.close()\n",
    "            \n",
    "            fopasm.close()\n",
    "            \n",
    "            # now delete the binary, we do not need it anymore.\n",
    "            # sub.call([\"rm\", file_path1])\n",
    "            \n",
    "            disassed += 1\n",
    "\n",
    "        else:\n",
    "            #print(\"Error: file does not exist - {:s}\".format(file_path))\n",
    "            error_count += 1\n",
    "           \n",
    "        counter += 1\n",
    "        if (counter % 1000) == 0: # print progress\n",
    "            print('Disassembled: {:d} - {:s}'.format(counter, file_path))    \n",
    " \n",
    "\n",
    "    print(\"Disassembled {:d} ELF binaries with {:d} file path errors.\".format(disassed, error_count))\n",
    "    \n",
    "    #sub.call([\"mv\", \"*.asm\", \"/opt/vs/asm\"])\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: unknown - ELF 32-bit MSB  executable PowerPC or cisco 4500 version 1 (SYSV) statically linked not stripped\n",
      "Found: unknown - ELF 32-bit LSB  executable MIPS MIPS-I version 1 (SYSV) statically linked not stripped\n",
      "Got 2 ELF filenames.\n",
      "Disassembling 2 binary ELF files.\n",
      "Disassembled 2 ELF binaries with 0 file path errors.\n"
     ]
    }
   ],
   "source": [
    "ext_drive = '/opt/vs/train1/'\n",
    "packer_id_file = 'data/sorted-packer-id-features-vs251.csv'\n",
    "file_id_file = 'data/sorted-file-id-features-vs251.csv'\n",
    "trid_id_file = 'data/sorted-trid-id-features-vs251.csv'\n",
    "    \n",
    "unflist, fidlist = get_elf_file_list(ext_drive, packer_id_file, file_id_file, trid_id_file)\n",
    "\n",
    "disassemble_elf_binaries(unflist, fidlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: unknown - ELF 32-bit MSB  executable PowerPC or cisco 4500 version 1 (SYSV) statically linked not stripped\n",
      "Found: unknown - ELF 32-bit LSB  executable ARM version 1 statically linked not stripped\n",
      "Found: unknown - ELF 32-bit LSB  executable Intel 80386 version 1 (SYSV) dynamically linked (uses shared libs) for GNU/Linux 2.0.0 stripped\n",
      "Got 3 ELF filenames.\n",
      "Disassembling 3 binary ELF files.\n",
      "Disassembled 3 ELF binaries with 0 file path errors.\n"
     ]
    }
   ],
   "source": [
    "ext_drive = '/opt/vs/train2/'\n",
    "packer_id_file = 'data/sorted-packer-id-features-vs252.csv'\n",
    "file_id_file = 'data/sorted-file-id-features-vs252.csv'\n",
    "trid_id_file = 'data/sorted-trid-id-features-vs252.csv'\n",
    "    \n",
    "unflist, fidlist = get_elf_file_list(ext_drive, packer_id_file, file_id_file, trid_id_file)\n",
    "\n",
    "disassemble_elf_binaries(unflist, fidlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: unknown - ELF 32-bit LSB  executable ARM EABI4 version 1 (SYSV) statically linked for GNU/Linux 2.6.14 stripped\n",
      "Found: unknown - ELF 32-bit LSB  executable Intel 80386 version 1 (SYSV) statically linked for GNU/Linux 2.2.5 not stripped\n",
      "Found: unknown - ELF 32-bit LSB  executable Intel 80386 version 1 (GNU/Linux) statically linked for GNU/Linux 2.6.18 not stripped\n",
      "Found: unknown - ELF 32-bit LSB  executable Intel 80386 version 1 (SYSV) statically linked for GNU/Linux 2.6.9 not stripped\n",
      "Found: unknown - ELF 32-bit LSB  executable ARM EABI5 version 1 (SYSV) statically linked for GNU/Linux 2.6.16 not stripped\n",
      "Got 5 ELF filenames.\n",
      "Disassembling 5 binary ELF files.\n",
      "Disassembled 5 ELF binaries with 0 file path errors.\n"
     ]
    }
   ],
   "source": [
    "ext_drive = '/opt/vs/train3/'\n",
    "packer_id_file = 'data/sorted-packer-id-features-vs263.csv'\n",
    "file_id_file = 'data/sorted-file-id-features-vs263.csv'\n",
    "trid_id_file = 'data/sorted-trid-id-features-vs263.csv'\n",
    "    \n",
    "unflist, fidlist = get_elf_file_list(ext_drive, packer_id_file, file_id_file, trid_id_file)\n",
    "\n",
    "disassemble_elf_binaries(unflist, fidlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ext_drive = '/opt/vs/train4/'\n",
    "packer_id_file = 'data/sorted-packer-id-features-vs264.csv'\n",
    "file_id_file = 'data/sorted-file-id-features-vs264.csv'\n",
    "trid_id_file = 'data/sorted-trid-id-features-vs264.csv'\n",
    "    \n",
    "unflist, fidlist = get_elf_file_list(ext_drive, packer_id_file, file_id_file, trid_id_file)\n",
    "\n",
    "disassemble_elf_binaries(unflist, fidlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fip = open('data/amd64-instruction-set.txt')\n",
    "inlines = fip.readlines()\n",
    "inlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opcode_list = []\n",
    "for line in inlines:\n",
    "    tokens = line.rstrip()\n",
    "    opcode_list.append(tokens.lower())\n",
    "    \n",
    "opcode_str = \"[\\'\" + \"','\".join(opcode_list) + \"\\']\" \n",
    "opcode_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fip = open('data/arm-instruction-set.txt')\n",
    "inlines = fip.readlines()\n",
    "inlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['adc','msr','add','mul','and','mvn','b','orr','bic','rsb','bl','rsc','bx','sbc','cdp','smlal','cmn','smull','cmp','stc','eor','stm','ldc','str','ldm','strb','ldr','strbt','ldrb','strh','ldrbt','strt','ldrh','sub','ldrsb','swi','ldrsh','swp','ldrt','swpb','mcr','teq','mla','tst','mov','umlal','mrc','umull','mrs']\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opcode_list = []\n",
    "for line in inlines:\n",
    "    tokens = line.split()\n",
    "    opcode_list.append(tokens[0].lower())\n",
    "    \n",
    "opcode_str = \"[\\'\" + \"','\".join(opcode_list) + \"\\']\" \n",
    "opcode_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fip = open('data/sparc-instruction-set.txt')\n",
    "inlines = fip.readlines()\n",
    "inlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opcode_list = []\n",
    "for line in inlines:\n",
    "    tokens = line.split()\n",
    "    opcode_list.append(tokens[0].lower())\n",
    "    \n",
    "opcode_str = \"[\\'\" + \"','\".join(opcode_list) + \"\\']\" \n",
    "opcode_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fip = open('data/powerpc-instruction-set.txt')\n",
    "inlines = fip.readlines()\n",
    "inlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opcode_list = []\n",
    "for line in inlines:\n",
    "    tokens = line.replace('[', ' ').split()\n",
    "    opcode_list.append(tokens[0].lower())\n",
    "    \n",
    "opcode_str = \"[\\'\" + \"','\".join(opcode_list) + \"\\']\" \n",
    "opcode_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(opcode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fip = open('data/powerpc-version-202-instruction-set.txt')\n",
    "inlines = fip.readlines()\n",
    "inlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opcode_list = []\n",
    "for line in inlines:\n",
    "    tokens = line.replace('[', ' ').rstrip().split()\n",
    "    opcode_list.append(tokens[0].lower())\n",
    "    \n",
    "opcode_str = \"[\\'\" + \"','\".join(opcode_list) + \"\\']\" \n",
    "opcode_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(opcode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fip = open('data/motorola-instruction-set.txt')\n",
    "inlines = fip.readlines()\n",
    "inlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fip = open('data/mips-instruction-set.txt')\n",
    "inlines = fip.readlines()\n",
    "inlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> abbde81d7f4733c16046cbd8ee7409d3,ELF 32-bit MSB  executable PowerPC or cisco 4500 version 1 (SYSV) statically linked not stripped,56\n",
      "\n",
      "-> f04f278048fc082dd5d0f34efa3c05f8,ELF 32-bit LSB  executable MIPS MIPS-I version 1 (SYSV) statically linked not stripped,475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check file id strings for ELF executables\n",
    "fip = open('data/sorted-file-id-features-vs251.csv')\n",
    "inlines = fip.readlines()\n",
    "for line in inlines:\n",
    "    if \"ELF\" in line:\n",
    "        print(\"-> {:s}\".format(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> c6813bcaf9a2801973e9c44fe75ef75b,ELF 32-bit MSB  executable PowerPC or cisco 4500 version 1 (SYSV) statically linked not stripped,56\n",
      "\n",
      "-> cbb492024bdd2484f39893ab77da0cae,ELF 32-bit LSB  executable ARM version 1 statically linked not stripped,216\n",
      "\n",
      "-> fa390c69553d757c3a10737a0a8604dc,ELF 32-bit LSB  executable Intel 80386 version 1 (SYSV) dynamically linked (uses shared libs) for GNU/Linux 2.0.0 stripped,463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fip = open('data/sorted-file-id-features-vs252.csv')\n",
    "inlines = fip.readlines()\n",
    "for line in inlines:\n",
    "    if \"ELF\" in line:\n",
    "        print(\"-> {:s}\".format(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> 480813ec6548a4e55245a0e446e63c36,ELF 32-bit LSB  executable ARM EABI4 version 1 (SYSV) statically linked for GNU/Linux 2.6.14 stripped,188\n",
      "\n",
      "-> 5b88e0490dd764e66e13c8a543099c9d,ELF 32-bit LSB  executable Intel 80386 version 1 (SYSV) statically linked for GNU/Linux 2.2.5 not stripped,192\n",
      "\n",
      "-> 62d33be03ef3bc9c81d703898fc0e18c,ELF 32-bit LSB  executable Intel 80386 version 1 (GNU/Linux) statically linked for GNU/Linux 2.6.18 not stripped,349\n",
      "\n",
      "-> 7a891a96d6af45865e5fe6142b40eb77,ELF 32-bit LSB  executable Intel 80386 version 1 (SYSV) statically linked for GNU/Linux 2.6.9 not stripped,447\n",
      "\n",
      "-> af8970eb045a77ad1c427eb6333c9efd,ELF 32-bit LSB  executable ARM EABI5 version 1 (SYSV) statically linked for GNU/Linux 2.6.16 not stripped,176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fip = open('data/sorted-file-id-features-vs263.csv')\n",
    "inlines = fip.readlines()\n",
    "for line in inlines:\n",
    "    if \"ELF\" in line:\n",
    "        print(\"-> {:s}\".format(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fip = open('data/sorted-file-id-features-vs264.csv')\n",
    "inlines = fip.readlines()\n",
    "for line in inlines:\n",
    "    if \"ELF\" in line:\n",
    "        print(\"-> {:s}\".format(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i   binutils                        - GNU assembler, linker and binary utilities\\n',\n",
       " 'p   binutils:i386                   - GNU assembler, linker and binary utilities\\n',\n",
       " 'p   binutils-aarch64-linux-gnu      - GNU binary utilities, for aarch64-linux-gn\\n',\n",
       " 'p   binutils-aarch64-linux-gnu:i386 - GNU binary utilities, for aarch64-linux-gn\\n',\n",
       " 'p   binutils-arm-linux-gnueabi      - GNU binary utilities, for arm-linux-gnueab\\n',\n",
       " 'p   binutils-arm-linux-gnueabi:i386 - GNU binary utilities, for arm-linux-gnueab\\n',\n",
       " 'p   binutils-arm-linux-gnueabihf    - GNU binary utilities, for arm-linux-gnueab\\n',\n",
       " 'p   binutils-arm-linux-gnueabihf:i3 - GNU binary utilities, for arm-linux-gnueab\\n',\n",
       " 'p   binutils-arm-none-eabi          - GNU assembler, linker and binary utilities\\n',\n",
       " 'p   binutils-arm-none-eabi:i386     - GNU assembler, linker and binary utilities\\n',\n",
       " \"p   binutils-avr                    - Binary utilities supporting Atmel's AVR ta\\n\",\n",
       " \"p   binutils-avr:i386               - Binary utilities supporting Atmel's AVR ta\\n\",\n",
       " 'p   binutils-dev                    - GNU binary utilities (BFD development file\\n',\n",
       " 'p   binutils-dev:i386               - GNU binary utilities (BFD development file\\n',\n",
       " 'p   binutils-doc                    - Documentation for the GNU assembler, linke\\n',\n",
       " 'v   binutils-gold                   -                                           \\n',\n",
       " 'v   binutils-gold:i386              -                                           \\n',\n",
       " 'p   binutils-h8300-hms              - GNU binary utilities, for h8300-hitachi-co\\n',\n",
       " 'p   binutils-h8300-hms:i386         - GNU binary utilities, for h8300-hitachi-co\\n',\n",
       " \"p   binutils-m68hc1x                - binary utilities that support Motorola's 6\\n\",\n",
       " \"p   binutils-m68hc1x:i386           - binary utilities that support Motorola's 6\\n\",\n",
       " 'p   binutils-mingw-w64              - Cross-binutils for Win32 and Win64 using M\\n',\n",
       " 'p   binutils-mingw-w64-i686         - Cross-binutils for Win32 (x86) using MinGW\\n',\n",
       " 'p   binutils-mingw-w64-i686:i386    - Cross-binutils for Win32 (x86) using MinGW\\n',\n",
       " 'p   binutils-mingw-w64-x86-64       - Cross-binutils for Win64 (x64) using MinGW\\n',\n",
       " 'p   binutils-mingw-w64-x86-64:i386  - Cross-binutils for Win64 (x64) using MinGW\\n',\n",
       " \"p   binutils-msp430                 - Binary utilities supporting TI's MSP430 ta\\n\",\n",
       " \"p   binutils-msp430:i386            - Binary utilities supporting TI's MSP430 ta\\n\",\n",
       " 'p   binutils-multiarch              - Binary utilities that support multi-arch t\\n',\n",
       " 'p   binutils-multiarch:i386         - Binary utilities that support multi-arch t\\n',\n",
       " 'p   binutils-multiarch-dev          - GNU binary utilities that support multi-ar\\n',\n",
       " 'p   binutils-multiarch-dev:i386     - GNU binary utilities that support multi-ar\\n',\n",
       " 'p   binutils-powerpc-linux-gnu      - GNU binary utilities, for powerpc-linux-gn\\n',\n",
       " 'p   binutils-powerpc-linux-gnu:i386 - GNU binary utilities, for powerpc-linux-gn\\n',\n",
       " 'p   binutils-powerpc64le-linux-gnu  - GNU binary utilities, for powerpc64le-linu\\n',\n",
       " 'p   binutils-powerpc64le-linux-gnu: - GNU binary utilities, for powerpc64le-linu\\n',\n",
       " 'p   binutils-source                 - GNU assembler, linker and binary utilities\\n',\n",
       " 'p   binutils-static                 - statically linked binutils tools          \\n',\n",
       " 'p   binutils-static:i386            - statically linked binutils tools          \\n',\n",
       " 'p   binutils-z80                    - GNU binary utilities for the z80-unknown-c\\n',\n",
       " 'p   binutils-z80:i386               - GNU binary utilities for the z80-unknown-c\\n',\n",
       " 'v   elf-binutils                    -                                           \\n',\n",
       " 'v   elf-binutils:i386               -                                           \\n',\n",
       " 'p   mingw32-binutils                - Minimalist GNU win32 (cross) binutils     \\n',\n",
       " 'p   mingw32-binutils:i386           - Minimalist GNU win32 (cross) binutils     \\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fip = open(\"/home/derek/binutils.txt\")\n",
    "inlines = fip.readlines()\n",
    "inlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apt install binutils binutils binutils-aarch64-linux-gnu binutils-aarch64-linux-gnu binutils-arm-linux-gnueabi binutils-arm-linux-gnueabi binutils-arm-linux-gnueabihf binutils-arm-linux-gnueabihf binutils-arm-none-eabi binutils-arm-none-eabi binutils-avr binutils-avr binutils-dev binutils-dev binutils-doc binutils-gold binutils-gold binutils-h8300-hms binutils-h8300-hms binutils-m68hc1x binutils-m68hc1x binutils-mingw-w64 binutils-mingw-w64-i686 binutils-mingw-w64-i686 binutils-mingw-w64-x86-64 binutils-mingw-w64-x86-64 binutils-msp430 binutils-msp430 binutils-multiarch binutils-multiarch binutils-multiarch-dev binutils-multiarch-dev binutils-powerpc-linux-gnu binutils-powerpc-linux-gnu binutils-powerpc64le-linux-gnu binutils-powerpc64le-linux-gnu binutils-source binutils-static binutils-static binutils-z80 binutils-z80 elf-binutils elf-binutils mingw32-binutils mingw32-binutils'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package_list = []\n",
    "for line in inlines:\n",
    "    tokens = line.replace(\":\", \" \").split()\n",
    "    package_list.append(tokens[1])\n",
    "    \n",
    "command = \"apt install \" + \" \".join(package_list)\n",
    "command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i   binutils                        - GNU assembler, linker and binary utilities\\n',\n",
       " 'p   binutils:i386                   - GNU assembler, linker and binary utilities\\n',\n",
       " 'p   binutils-aarch64-linux-gnu      - GNU binary utilities, for aarch64-linux-gn\\n',\n",
       " 'p   binutils-aarch64-linux-gnu:i386 - GNU binary utilities, for aarch64-linux-gn\\n',\n",
       " 'p   binutils-alpha-linux-gnu        - GNU binary utilities, for alpha-linux-gnu \\n',\n",
       " 'p   binutils-alpha-linux-gnu:i386   - GNU binary utilities, for alpha-linux-gnu \\n',\n",
       " 'p   binutils-arm-linux-gnueabi      - GNU binary utilities, for arm-linux-gnueab\\n',\n",
       " 'p   binutils-arm-linux-gnueabi:i386 - GNU binary utilities, for arm-linux-gnueab\\n',\n",
       " 'p   binutils-arm-linux-gnueabihf    - GNU binary utilities, for arm-linux-gnueab\\n',\n",
       " 'p   binutils-arm-linux-gnueabihf:i3 - GNU binary utilities, for arm-linux-gnueab\\n',\n",
       " 'p   binutils-arm-none-eabi          - GNU assembler, linker and binary utilities\\n',\n",
       " 'p   binutils-arm-none-eabi:i386     - GNU assembler, linker and binary utilities\\n',\n",
       " \"p   binutils-avr                    - Binary utilities supporting Atmel's AVR ta\\n\",\n",
       " \"p   binutils-avr:i386               - Binary utilities supporting Atmel's AVR ta\\n\",\n",
       " 'p   binutils-dev                    - GNU binary utilities (BFD development file\\n',\n",
       " 'p   binutils-dev:i386               - GNU binary utilities (BFD development file\\n',\n",
       " 'p   binutils-doc                    - Documentation for the GNU assembler, linke\\n',\n",
       " 'v   binutils-gold                   -                                           \\n',\n",
       " 'v   binutils-gold:i386              -                                           \\n',\n",
       " 'p   binutils-h8300-hms              - GNU binary utilities, for h8300-hitachi-co\\n',\n",
       " 'p   binutils-h8300-hms:i386         - GNU binary utilities, for h8300-hitachi-co\\n',\n",
       " 'p   binutils-hppa-linux-gnu         - GNU binary utilities, for hppa-linux-gnu t\\n',\n",
       " 'p   binutils-hppa-linux-gnu:i386    - GNU binary utilities, for hppa-linux-gnu t\\n',\n",
       " 'v   binutils-hppa64                 -                                           \\n',\n",
       " 'v   binutils-hppa64:i386            -                                           \\n',\n",
       " 'p   binutils-hppa64-linux-gnu       - GNU assembler, linker and binary utilities\\n',\n",
       " 'p   binutils-hppa64-linux-gnu:i386  - GNU assembler, linker and binary utilities\\n',\n",
       " \"p   binutils-m68hc1x                - binary utilities that support Motorola's 6\\n\",\n",
       " \"p   binutils-m68hc1x:i386           - binary utilities that support Motorola's 6\\n\",\n",
       " 'p   binutils-m68k-linux-gnu         - GNU binary utilities, for m68k-linux-gnu t\\n',\n",
       " 'p   binutils-m68k-linux-gnu:i386    - GNU binary utilities, for m68k-linux-gnu t\\n',\n",
       " 'p   binutils-mingw-w64              - Cross-binutils for Win32 and Win64 using M\\n',\n",
       " 'p   binutils-mingw-w64-i686         - Cross-binutils for Win32 (x86) using MinGW\\n',\n",
       " 'p   binutils-mingw-w64-i686:i386    - Cross-binutils for Win32 (x86) using MinGW\\n',\n",
       " 'p   binutils-mingw-w64-x86-64       - Cross-binutils for Win64 (x64) using MinGW\\n',\n",
       " 'p   binutils-mingw-w64-x86-64:i386  - Cross-binutils for Win64 (x64) using MinGW\\n',\n",
       " 'p   binutils-mips-linux-gnu         - GNU binary utilities, for mips-linux-gnu t\\n',\n",
       " 'p   binutils-mips-linux-gnu:i386    - GNU binary utilities, for mips-linux-gnu t\\n',\n",
       " 'p   binutils-mips64-linux-gnuabi64  - GNU binary utilities, for mips64-linux-gnu\\n',\n",
       " 'p   binutils-mips64-linux-gnuabi64: - GNU binary utilities, for mips64-linux-gnu\\n',\n",
       " 'p   binutils-mips64el-linux-gnuabi6 - GNU binary utilities, for mips64el-linux-g\\n',\n",
       " 'p   binutils-mips64el-linux-gnuabi6 - GNU binary utilities, for mips64el-linux-g\\n',\n",
       " 'p   binutils-mipsel-linux-gnu       - GNU binary utilities, for mipsel-linux-gnu\\n',\n",
       " 'p   binutils-mipsel-linux-gnu:i386  - GNU binary utilities, for mipsel-linux-gnu\\n',\n",
       " \"p   binutils-msp430                 - Binary utilities supporting TI's MSP430 ta\\n\",\n",
       " \"p   binutils-msp430:i386            - Binary utilities supporting TI's MSP430 ta\\n\",\n",
       " 'p   binutils-multiarch              - Binary utilities that support multi-arch t\\n',\n",
       " 'p   binutils-multiarch:i386         - Binary utilities that support multi-arch t\\n',\n",
       " 'p   binutils-multiarch-dev          - GNU binary utilities that support multi-ar\\n',\n",
       " 'p   binutils-multiarch-dev:i386     - GNU binary utilities that support multi-ar\\n',\n",
       " 'p   binutils-powerpc-linux-gnu      - GNU binary utilities, for powerpc-linux-gn\\n',\n",
       " 'p   binutils-powerpc-linux-gnu:i386 - GNU binary utilities, for powerpc-linux-gn\\n',\n",
       " 'p   binutils-powerpc-linux-gnuspe   - GNU binary utilities, for powerpc-linux-gn\\n',\n",
       " 'p   binutils-powerpc-linux-gnuspe:i - GNU binary utilities, for powerpc-linux-gn\\n',\n",
       " 'p   binutils-powerpc64-linux-gnu    - GNU binary utilities, for powerpc64-linux-\\n',\n",
       " 'p   binutils-powerpc64-linux-gnu:i3 - GNU binary utilities, for powerpc64-linux-\\n',\n",
       " 'p   binutils-powerpc64le-linux-gnu  - GNU binary utilities, for powerpc64le-linu\\n',\n",
       " 'p   binutils-powerpc64le-linux-gnu: - GNU binary utilities, for powerpc64le-linu\\n',\n",
       " 'p   binutils-s390x-linux-gnu        - GNU binary utilities, for s390x-linux-gnu \\n',\n",
       " 'p   binutils-s390x-linux-gnu:i386   - GNU binary utilities, for s390x-linux-gnu \\n',\n",
       " 'p   binutils-sh4-linux-gnu          - GNU binary utilities, for sh4-linux-gnu ta\\n',\n",
       " 'p   binutils-sh4-linux-gnu:i386     - GNU binary utilities, for sh4-linux-gnu ta\\n',\n",
       " 'p   binutils-source                 - GNU assembler, linker and binary utilities\\n',\n",
       " 'p   binutils-sparc64-linux-gnu      - GNU binary utilities, for sparc64-linux-gn\\n',\n",
       " 'p   binutils-sparc64-linux-gnu:i386 - GNU binary utilities, for sparc64-linux-gn\\n',\n",
       " 'p   binutils-z80                    - GNU binary utilities for the z80-unknown-c\\n',\n",
       " 'p   binutils-z80:i386               - GNU binary utilities for the z80-unknown-c\\n',\n",
       " 'v   elf-binutils                    -                                           \\n',\n",
       " 'v   elf-binutils:i386               -                                           \\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fip = open(\"/home/derek/binutils.txt\")\n",
    "inlines = fip.readlines()\n",
    "inlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apt install binutils binutils-aarch64-linux-gnu binutils-alpha-linux-gnu binutils-arm-linux-gnueabi binutils-arm-linux-gnueabihf binutils-arm-linux-gnueabihf:i3 binutils-arm-none-eabi binutils-avr binutils-dev binutils-doc binutils-gold binutils-h8300-hms binutils-hppa-linux-gnu binutils-hppa64 binutils-hppa64-linux-gnu binutils-m68hc1x binutils-m68k-linux-gnu binutils-mingw-w64 binutils-mingw-w64-i686 binutils-mingw-w64-x86-64 binutils-mips-linux-gnu binutils-mips64-linux-gnuabi64 binutils-mips64-linux-gnuabi64: binutils-mips64el-linux-gnuabi6 binutils-mips64el-linux-gnuabi6 binutils-mipsel-linux-gnu binutils-msp430 binutils-multiarch binutils-multiarch-dev binutils-powerpc-linux-gnu binutils-powerpc-linux-gnuspe binutils-powerpc-linux-gnuspe:i binutils-powerpc64-linux-gnu binutils-powerpc64-linux-gnu:i3 binutils-powerpc64le-linux-gnu binutils-powerpc64le-linux-gnu: binutils-s390x-linux-gnu binutils-sh4-linux-gnu binutils-source binutils-sparc64-linux-gnu binutils-z80 elf-binutils'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package_list = []\n",
    "for line in inlines:\n",
    "    if \":i386\" not in line:\n",
    "        tokens = line.split()\n",
    "        package_list.append(tokens[1])\n",
    "    \n",
    "command = \"apt install \" + \" \".join(package_list)\n",
    "command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x86_registers = ['edx','esi','es','fs','ds','ss','gs','cs','ah','al',\n",
    "                 'ax','bh','bl','bx','ch','cl','cx','dh','dl','dx',\n",
    "                 'eax','ebp','ebx','ecx','edi','esp']\n",
    "\n",
    "x86_opcodes = ['add','al','bt','call','cdq','cld','cli','cmc','cmp','const','cwd','daa','db'\n",
    "                ,'dd','dec','dw','endp','ends','faddp','fchs','fdiv','fdivp','fdivr','fild'\n",
    "                ,'fistp','fld','fstcw','fstcwimul','fstp','fword','fxch','imul','in','inc'\n",
    "                ,'ins','int','jb','je','jg','jge','jl','jmp','jnb','jno','jnz','jo','jz'\n",
    "                ,'lea','loope','mov','movzx','mul','near','neg','not','or','out','outs'\n",
    "                ,'pop','popf','proc','push','pushf','rcl','rcr','rdtsc','rep','ret','retn'\n",
    "                ,'rol','ror','sal','sar','sbb','scas','setb','setle','setnle','setnz'\n",
    "                ,'setz','shl','shld','shr','sidt','stc','std','sti','stos','sub','test'\n",
    "                ,'wait','xchg','xor']\n",
    "\n",
    "amd64_registers = ['rax','rbx','rcx','rdx','rsi','rdi','rbp','rsp','r8','r9','r10','r11','r12','r13','r14','r15']\n",
    "\n",
    "amd64_opcodes = ['aaa','aad','aam','aas','adc','add','and','andn','bextr','bextr','blcfill','blci','blcic',\n",
    "                 'blcmsk','blcs','blsfill','blsi','blsic','blsmsk','blsr','bound','bsf','bsr','bswap','bt',\n",
    "                 'btc','btr','bts','bzhi','call','cbw','cwde','cdqe','cwd','cdq','cqo','clc','cld','clflush','cmc','cmov',\n",
    "                 'cmp','cmps','cmpsb','cmpsw','cmpsd','cmpsq','cmpxchg','cmpxchg8b','cmpxchg16b','cpuid',\n",
    "                 'crc32','daa','das','dec','div','enter','idiv','imul','in','inc','ins','insb','insw','insd',\n",
    "                 'int','into','jcxz','jecxz','jrcxz','jmp','lahf','lds','les','lfs','lgs','lss','lea','leave','lfence',\n",
    "                 'llwpcb','lods','lodsb','lodsw','lodsd','lodsq','loop','loope','loopne','loopnz','loopz','lwpins',\n",
    "                 'lwpval','lzcnt','mfence','mov','movbe','movd','movmskpd','movmskps','movnti','movs','movsb',\n",
    "                 'movsw','movsd','movsq','movsx','movsxd','movzx','mul','mulx','neg','nop','not','or','out',\n",
    "                 'outs','outsb','outsw','outsd','pause','pdep','pext','pop','popa','popad','popcnt','popf','popfd',\n",
    "                 'popfq','prefetch','prefetchw','prefetch','push','pusha','pushad','pushf','pushfd','pushfq',\n",
    "                 'rcl','rcr','rdfsbase','rdgsbase','rdrand','ret','rol','ror','rorx','sahf','sal','shl','sar','sarx',\n",
    "                 'sbb','scas','scasb','scasw','scasd','scasq','set','sfence','shl','shld','shlx',\n",
    "                 'shr','shrd','shrx','slwpcb','stc','std','stos','stosb','stosw','stosd','stosq','sub','t1mskc',\n",
    "                 'test','tzcnt','tzmsk','wrfsbase','wrgsbase','xadd','xchg','xlat','xlatb','xor','arpl','clgi','cli',\n",
    "                 'clts','hlt','int','invd','invlpg','invlpga','iret','iretd','iretq','lar','lgdt','lidt','lldt',\n",
    "                 'lmsw','lsl','ltr','monitor','monitorx','mwait','mwaitx','rdmsr','rdpmc','rdtsc','rdtscp',\n",
    "                 'rsm','sgdt','sidt','skinit','sldt','smsw','sti','stgi','str','swapgs',\n",
    "                 'syscall','sysenter','sysexit','sysret','ud2','verr','verw',\n",
    "                 'vmload','vmmcall','vmrun','vmsave','wbinvd','wrmsr']\n",
    "\n",
    "MIPS_registers = []\n",
    "\n",
    "MIPS_opcodes = []\n",
    "\n",
    "SPARC_registers = []\n",
    "\n",
    "SPARC_opcodes = []\n",
    "\n",
    "ARM_registers = ['r0','r1','r2','r3','r4','r5','r6','r7','r8','r9','r10','r11','r12','r13','r14','r15','cpsr']\n",
    "\n",
    "ARM_opcodes = ['adc','msr','add','mul','and','mvn','b','orr','bic','rsb','bl','rsc','bx','sbc','cdp','smlal','cmn','smull',\n",
    "               'cmp','stc','eor','stm','ldc','str','ldm','strb','ldr','strbt','ldrb','strh','ldrbt','strt','ldrh','sub','ldrsb','swi',\n",
    "               'ldrsh','swp','ldrt','swpb','mcr','teq','mla','tst','mov','umlal','mrc','umull','mrs']\n",
    "\n",
    "Motorola_registers = ['d0','d1','d2','d3','d4','d5','d6','d7','a0','a1','a2','a3','a4','a5','a6','a7','usp','ssp']\n",
    "\n",
    "Motorola_opcodes = []\n",
    "\n",
    "PowerPC_registers = ['r0','r1','r2','r3','r4','r5','r6','r7','r8','r9','r10','r11','r12','r13','r14','r15',\n",
    "                    'r16','r17','r18','r19','r20','r21','r22','r23','r24','r25','r26','r27','r28','r29','r30','r31']\n",
    "\n",
    "PowerPC_opcodes = ['add','addc','adde','addi','addic','addic.','addis','addme','addze','and','andc','andi.','andis.',\n",
    "                   'b','bc','bcctr','bclr','cmp','cmpi','cmpl','cmpli','cntlzd','cntlzw','crand','crandc','creqv',\n",
    "                   'crnand','crnor','cror','crorc','crxor','dcbf','dcbst','dcbt','dcbtst','dcbz','divd','divdu',\n",
    "                   'divw','divwu','eciwx','ecowx','eieio','eqv','extsb','extsh','extsw','fabs','fadd','fadds',\n",
    "                   'fcfid','fcmpo','fcmpu','fctid','fctidz','fctiw','fctiwz','fdiv','fdivs','fmadd','fmadds',\n",
    "                   'fmr','fmsub','fmsubs','fmul','fmuls','fnabs','fneg','fnmadd','fnmadds','fnmsub','fnmsubs',\n",
    "                   'fre','fres','frsp','frsqrte','frsqrtes','fsel','fsqrt','fsqrts','fsub','fsubs','hrfid','icbi',\n",
    "                   'isync','lbz','lbzu','lbzux','lbzx','ld','ldarx','ldu','ldux','ldx','lfd','lfdu','lfdux','lfdx',\n",
    "                   'lfs','lfsu','lfsux','lfsx','lha','lhau','lhaux','lhax','lhbrx','lhz','lhzu','lhzux','lhzx','lmw',\n",
    "                   'lswi','lswx','lwa','lwarx','lwaux','lwax','lwbrx','lwz','lwzu','lwzux','lwzx','mcrf','mcrfs',\n",
    "                   'mcrxr','mfcr','mfocrf','mffs','mfmsr','mfspr','mfsr','mfsrin','mftb','mtcrf','mtocrf','mtfsb0',\n",
    "                   'mtfsb1','mtfsf','mtfsfi','mtmsr','mtmsrd','mtspr','mtsr','mtsrin','mulhd','mulhdu','mulhw','mulhwu',\n",
    "                   'mulld','mulli','mullw','nand','neg','nor','or','orc','ori','oris','popcntb','rfid','rldcl','rldcr',\n",
    "                   'rldic','rldicl','rldicr','rldimi','rlwimi','rlwinm','rlwnm','sc','slbia','slbie','slbmfee',\n",
    "                   'slbmfev','slbmte','sld','slw','srad','sradi','sraw','srawi','srd','srw','stb','stbu','stbux',\n",
    "                   'stbx','std','stdcx.','stdu','stdux','stdx','stfd','stfdu','stfdux','stfdx','stfiwx','stfs',\n",
    "                   'stfsu','stfsux','stfsx','sth','sthbrx','sthu','sthux','sthx','stmw','stswi','stswx','stw',\n",
    "                   'stwbrx','stwcx.','stwu','stwux','stwx','subf','subfc','subfe','subfic','subfme','subfze',\n",
    "                   'sync','td','tdi','tlbia','tlbie','tlbsync','tw','twi','xor','xori','xoris']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  /* XScale instructions.  */\\n',\n",
       " '  {ARM_FEATURE_COPROC (ARM_CEXT_XSCALE),\\n',\n",
       " '    0x0e200010, 0x0fff0ff0,\\n',\n",
       " '    \"mia%c\\\\tacc0, %0-3r, %12-15r\"},\\n',\n",
       " '  {ARM_FEATURE_COPROC (ARM_CEXT_XSCALE),\\n',\n",
       " '    0x0e280010, 0x0fff0ff0,\\n',\n",
       " '    \"miaph%c\\\\tacc0, %0-3r, %12-15r\"},\\n',\n",
       " '  {ARM_FEATURE_COPROC (ARM_CEXT_XSCALE),\\n',\n",
       " '    0x0e2c0010, 0x0ffc0ff0, \"mia%17\\'T%17`B%16\\'T%16`B%c\\\\tacc0, %0-3r, %12-15r\"},\\n',\n",
       " '  {ARM_FEATURE_COPROC (ARM_CEXT_XSCALE),\\n',\n",
       " '    0x0c400000, 0x0ff00fff, \"mar%c\\\\tacc0, %12-15r, %16-19r\"},\\n',\n",
       " '  {ARM_FEATURE_COPROC (ARM_CEXT_XSCALE),\\n',\n",
       " '    0x0c500000, 0x0ff00fff, \"mra%c\\\\t%12-15r, %16-19r, acc0\"},\\n',\n",
       " '\\n',\n",
       " '  /* Intel Wireless MMX technology instructions.  */\\n',\n",
       " '  {ARM_FEATURE_CORE_LOW (0), SENTINEL_IWMMXT_START, 0, \"\" },\\n',\n",
       " '  {ARM_FEATURE_COPROC (ARM_CEXT_IWMMXT),\\n',\n",
       " '    0x0e130130, 0x0f3f0fff, \"tandc%22-23w%c\\\\t%12-15r\"},\\n',\n",
       " '  {ARM_FEATURE_COPROC (ARM_CEXT_XSCALE),\\n',\n",
       " '    0x0e400010, 0x0ff00f3f, \"tbcst%6-7w%c\\\\t%16-19g, %12-15r\"},\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fip = open(\"data/arm-listing.txt\")\n",
    "inlines = fip.readlines()\n",
    "inlines[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse the contents of arm-dis.c in binutils and extract all the ARM opcodes.\n",
    "opcode_list = []\n",
    "counter = 0\n",
    "opcode = 'none'\n",
    "for line in inlines:\n",
    "    line = line.lstrip()\n",
    "    line = line.replace('\\\\t',' ')\n",
    "    if len(line) < 10:\n",
    "        continue\n",
    "    if line.startswith('{'):\n",
    "        continue\n",
    "    if line.startswith('\"'):\n",
    "        idx = line.find('%')\n",
    "        if idx > 0:\n",
    "            opcode = line[1:idx]\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        tokens = line.split()\n",
    "        if len(tokens) < 3:\n",
    "            continue\n",
    "        opcodestr = tokens[2]\n",
    "        idx = opcodestr.find('%')\n",
    "        if idx > 0:\n",
    "            opcode = opcodestr[1:idx]\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    if opcode not in opcode_list:\n",
    "        opcode_list.append(opcode)\n",
    "    \n",
    "opcode_str = \"[\\'\" + \"','\".join(opcode_list) + \"\\']\" \n",
    "opcode_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fip = open(\"data/m68k-opc.c\")\n",
    "inlines = fip.readlines()\n",
    "inlines[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse the contents of m68k-opc.c in binutils and extract all the Motorola opcodes.\n",
    "opcode_list = []\n",
    "counter = 0\n",
    "opcode = 'none'\n",
    "for line in inlines:\n",
    "    line = line.lstrip()\n",
    "    if len(line) < 10:\n",
    "        continue\n",
    "    if line.startswith(\"{\"):\n",
    "        line = line[2:]\n",
    "        idx = line.find(\"\\\"\")\n",
    "        if idx > 0:\n",
    "            opcode = line[:idx]\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        continue\n",
    "            \n",
    "    if opcode not in opcode_list:\n",
    "        opcode_list.append(opcode)\n",
    "    \n",
    "opcode_str = \"[\\'\" + \"','\".join(opcode_list) + \"\\']\" \n",
    "opcode_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fip = open(\"data/mips-instruction-set.txt\")\n",
    "inlines = fip.readlines()\n",
    "inlines[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse the contents of mips-instruction-set.txt and extract all the things.\n",
    "opcode_list = []\n",
    "counter = 0\n",
    "opcode = 'none'\n",
    "for line in inlines:\n",
    "    line = line.lstrip()\n",
    "    if len(line) < 10:\n",
    "        continue\n",
    "    if line.startswith(\"{\"):\n",
    "        line = line[2:]\n",
    "        idx = line.find(\"\\\"\")\n",
    "        if idx > 0:\n",
    "            opcode = line[:idx]\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    idx = opcode.find(\".\")\n",
    "    if idx > 0:\n",
    "        opcode = opcode[:idx]\n",
    "        \n",
    "    if opcode not in opcode_list:\n",
    "        opcode_list.append(opcode)\n",
    "    \n",
    "opcode_str = \"[\\'\" + \"','\".join(opcode_list) + \"\\']\" \n",
    "opcode_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fip = open(\"data/i386-opc.tbl\")\n",
    "inlines = fip.readlines()\n",
    "inlines[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse the contents of i386-opc.tbl from binutils and extract all the things.\n",
    "opcode_list = []\n",
    "counter = 0\n",
    "opcode = 'none'\n",
    "for line in inlines:\n",
    "    if len(line) < 10:\n",
    "        continue\n",
    "    if line.startswith(\"//\"):\n",
    "        continue\n",
    "        \n",
    "    line = line.replace(',', ' ')\n",
    "    tokens = line.split()\n",
    "    if len(tokens) > 0:\n",
    "        opcode = tokens[0]\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    idx = opcode.find(\".\")\n",
    "    if idx > 0:\n",
    "        opcode = opcode[:idx]\n",
    "        \n",
    "    if opcode not in opcode_list:\n",
    "        opcode_list.append(opcode)\n",
    "    \n",
    "opcode_str = \"[\\'\" + \"','\".join(opcode_list) + \"\\']\" \n",
    "opcode_str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
